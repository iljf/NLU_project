{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KLUE-RoBERTa연습.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPWnvtoD05PArB+IrdvjoBU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iljf/NLU_project_team1/blob/main/KLUE_RoBERTa%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random\n",
        "import tarfile\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CosineSimilarity, MSELoss\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Ur_9RlnTGEkt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jix9-YM1FlvU",
        "outputId": "5b438315-9e24-4555-88f0-2ef8abb78c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K87jYblGrsA",
        "outputId": "4a039461-2f5e-4d96-afdd-c96f7f910f07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Klue dataset 다운\n",
        "!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000067/data/klue-sts-v1.1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viHGeIbOGHB_",
        "outputId": "aa29891f-c7f3-4609-8ff5-4f1a2b0ba5d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-25 11:56:28--  https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000067/data/klue-sts-v1.1.tar.gz\n",
            "Resolving aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)... 52.218.240.130\n",
            "Connecting to aistages-prod-server-public.s3.amazonaws.com (aistages-prod-server-public.s3.amazonaws.com)|52.218.240.130|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1349881 (1.3M) [application/x-gzip]\n",
            "Saving to: ‘klue-sts-v1.1.tar.gz.1’\n",
            "\n",
            "klue-sts-v1.1.tar.g 100%[===================>]   1.29M  1.36MB/s    in 0.9s    \n",
            "\n",
            "2022-05-25 11:56:30 (1.36 MB/s) - ‘klue-sts-v1.1.tar.gz.1’ saved [1349881/1349881]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar_file = tarfile.open('/content/drive/MyDrive/NLP/klue-sts-v1.1.tar.gz')\n",
        "tar_file.extractall(path='/content/drive/MyDrive/NLP')\n",
        "tar_file.close()"
      ],
      "metadata": {
        "id": "whNcgW5vGyQy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_json('/content/drive/MyDrive/NLP/klue-sts-v1.1/klue-sts-v1.1_train.json')\n",
        "test = pd.read_json('/content/drive/MyDrive/NLP/klue-sts-v1.1/klue-sts-v1.1_dev.json')"
      ],
      "metadata": {
        "id": "mVDg9uz7Hqg9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "UKYRLfRIPb_k",
        "outputId": "a17c63be-15ae-4172-faba-883e86701e8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      guid           source  \\\n",
              "0  klue-sts-v1_train_00000       airbnb-rtt   \n",
              "1  klue-sts-v1_train_00001   policy-sampled   \n",
              "2  klue-sts-v1_train_00002  paraKQC-sampled   \n",
              "3  klue-sts-v1_train_00003   policy-sampled   \n",
              "4  klue-sts-v1_train_00004       airbnb-rtt   \n",
              "\n",
              "                                           sentence1  \\\n",
              "0                   숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.   \n",
              "1      위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.   \n",
              "2            회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.   \n",
              "3  긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...   \n",
              "4                        호스트의 답장이 늦으나, 개선될 것으로 보입니다.   \n",
              "\n",
              "                                    sentence2  \\\n",
              "0  숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.   \n",
              "1       시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.   \n",
              "2                  사람들이 주로 네이버 메일을 쓰는 이유를 알려줘   \n",
              "3   고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.   \n",
              "4                  호스트 응답이 늦었지만 개선될 것으로 보입니다.   \n",
              "\n",
              "                                              labels  \\\n",
              "0  {'label': 3.7, 'real-label': 3.714285714285714...   \n",
              "1  {'label': 0.0, 'real-label': 0.0, 'binary-labe...   \n",
              "2  {'label': 0.30000000000000004, 'real-label': 0...   \n",
              "3  {'label': 0.6000000000000001, 'real-label': 0....   \n",
              "4  {'label': 4.7, 'real-label': 4.714285714285714...   \n",
              "\n",
              "                                         annotations  \n",
              "0  {'agreement': '0:0:0:2:5:0', 'annotators': ['0...  \n",
              "1  {'agreement': '5:0:0:0:0:0', 'annotators': ['1...  \n",
              "2  {'agreement': '4:2:0:0:0:0', 'annotators': ['1...  \n",
              "3  {'agreement': '4:2:1:0:0:0', 'annotators': ['1...  \n",
              "4  {'agreement': '0:0:0:0:2:5', 'annotators': ['1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cadfc310-f99e-4039-a22a-3b14aea18839\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>klue-sts-v1_train_00000</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.</td>\n",
              "      <td>숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.</td>\n",
              "      <td>{'label': 3.7, 'real-label': 3.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:2:5:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>klue-sts-v1_train_00001</td>\n",
              "      <td>policy-sampled</td>\n",
              "      <td>위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.</td>\n",
              "      <td>시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.</td>\n",
              "      <td>{'label': 0.0, 'real-label': 0.0, 'binary-labe...</td>\n",
              "      <td>{'agreement': '5:0:0:0:0:0', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>klue-sts-v1_train_00002</td>\n",
              "      <td>paraKQC-sampled</td>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.</td>\n",
              "      <td>사람들이 주로 네이버 메일을 쓰는 이유를 알려줘</td>\n",
              "      <td>{'label': 0.30000000000000004, 'real-label': 0...</td>\n",
              "      <td>{'agreement': '4:2:0:0:0:0', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>klue-sts-v1_train_00003</td>\n",
              "      <td>policy-sampled</td>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...</td>\n",
              "      <td>고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.</td>\n",
              "      <td>{'label': 0.6000000000000001, 'real-label': 0....</td>\n",
              "      <td>{'agreement': '4:2:1:0:0:0', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>klue-sts-v1_train_00004</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>호스트의 답장이 늦으나, 개선될 것으로 보입니다.</td>\n",
              "      <td>호스트 응답이 늦었지만 개선될 것으로 보입니다.</td>\n",
              "      <td>{'label': 4.7, 'real-label': 4.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:0:2:5', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cadfc310-f99e-4039-a22a-3b14aea18839')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cadfc310-f99e-4039-a22a-3b14aea18839 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cadfc310-f99e-4039-a22a-3b14aea18839');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sDzeOChRR2J",
        "outputId": "f988af14-3b39-4c77-a1de-0370356336a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11668, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복문장 확인\n",
        "df1.duplicated(['sentence1', 'sentence2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk7ipMxARUuJ",
        "outputId": "e65a4e3a-779c-4fcb-e193-1e6af4f46e68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2-s4-0SRiVb",
        "outputId": "82d38755-fb24-4996-928a-10e3d2f9292a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "guid           0\n",
              "source         0\n",
              "sentence1      0\n",
              "sentence2      0\n",
              "labels         0\n",
              "annotations    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복문장 제거\n",
        "df1 = df1.drop_duplicates(['sentence1','sentence2'], keep='first', ignore_index=True)"
      ],
      "metadata": {
        "id": "I8fH9JwTRdGW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3종류의 라벨링 binaly 1이 같은문장 2가 다른문장 \n",
        "df1.labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsCvbDzyH2ML",
        "outputId": "9e94fb52-888f-48f2-c5de-a559def9162f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary-label': 1, 'label': 3.7, 'real-label': 3.714285714285714}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.labels[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d26OYTLQbCw",
        "outputId": "97cbf8ad-c4c0-4b09-d771-9e2180a14bae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary-label': 0,\n",
              " 'label': 0.30000000000000004,\n",
              " 'real-label': 0.33333333333333304}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 분리\n",
        "labels = df1.labels.to_list()\n",
        "labels = pd.DataFrame(labels)\n",
        "print(len(labels))\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "z3bsy5Z3Q88z",
        "outputId": "45f0f3b1-8d53-4a86-8a06-5873eb02a2f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11661\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label  real-label  binary-label\n",
              "0        3.7    3.714286             1\n",
              "1        0.0    0.000000             0\n",
              "2        0.3    0.333333             0\n",
              "3        0.6    0.571429             0\n",
              "4        4.7    4.714286             1\n",
              "...      ...         ...           ...\n",
              "11656    4.0    4.000000             1\n",
              "11657    0.0    0.000000             0\n",
              "11658    3.7    3.666667             1\n",
              "11659    4.7    4.714286             1\n",
              "11660    3.3    3.333333             1\n",
              "\n",
              "[11661 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0868bc89-7d1e-482f-9b2f-696424e5f5d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>real-label</th>\n",
              "      <th>binary-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.7</td>\n",
              "      <td>3.714286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.7</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11656</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11657</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11658</th>\n",
              "      <td>3.7</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11659</th>\n",
              "      <td>4.7</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11660</th>\n",
              "      <td>3.3</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11661 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0868bc89-7d1e-482f-9b2f-696424e5f5d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0868bc89-7d1e-482f-9b2f-696424e5f5d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0868bc89-7d1e-482f-9b2f-696424e5f5d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels['label'].value_counts()\n",
        "la1 = len(labels.loc[(labels['label'] >= 0) & (labels['real-label'] < 1.0)])\n",
        "la2 = len(labels.loc[(labels['label'] >= 1.0) & (labels['real-label'] < 2.0)])\n",
        "la3 = len(labels.loc[(labels['label'] >= 2.0) & (labels['real-label'] < 3.0)])\n",
        "la4 = len(labels.loc[(labels['label'] >= 3.0) & (labels['real-label'] < 4.0)])\n",
        "la5 = len(labels.loc[(labels['label'] >= 4.0) & (labels['real-label'] < 5.0)])\n",
        "\n",
        "print(f' Score 1미만인 데이터: {la1}\\n Score 2미만인 데이터: {la2}\\n Score 3미만인 데이터: {la3}\\n Score 4미만인 데이터: {la4}\\n Score 5미만인 데이터: {la5}')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK97PK24WUZG",
        "outputId": "8b1bc1b9-ee32-462a-d925-b48fc8193e92"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Score 1미만인 데이터: 4350\n",
            " Score 2미만인 데이터: 906\n",
            " Score 3미만인 데이터: 810\n",
            " Score 4미만인 데이터: 2852\n",
            " Score 5미만인 데이터: 2698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# binary-labele 은 score 3미만인 데이터로 이루어져 있다.\n",
        "labels['binary-label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d5lLoIWVib9",
        "outputId": "e98f7d32-3581-435a-8714-4c025e58adb4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6066\n",
              "1    5595\n",
              "Name: binary-label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1_1 = df1[['sentence1', 'sentence2']].join(labels['binary-label'])\n",
        "df1_1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-zlh2UppZfm1",
        "outputId": "99b96fdb-b6ec-4b46-e2fb-06daf62621d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence1  \\\n",
              "0                   숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.   \n",
              "1      위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.   \n",
              "2            회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.   \n",
              "3  긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...   \n",
              "4                        호스트의 답장이 늦으나, 개선될 것으로 보입니다.   \n",
              "\n",
              "                                    sentence2  binary-label  \n",
              "0  숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.             1  \n",
              "1       시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.             0  \n",
              "2                  사람들이 주로 네이버 메일을 쓰는 이유를 알려줘             0  \n",
              "3   고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.             0  \n",
              "4                  호스트 응답이 늦었지만 개선될 것으로 보입니다.             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5b393a1-67ea-4c61-9d42-7860f2a0dff9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>binary-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.</td>\n",
              "      <td>숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.</td>\n",
              "      <td>시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.</td>\n",
              "      <td>사람들이 주로 네이버 메일을 쓰는 이유를 알려줘</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...</td>\n",
              "      <td>고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호스트의 답장이 늦으나, 개선될 것으로 보입니다.</td>\n",
              "      <td>호스트 응답이 늦었지만 개선될 것으로 보입니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5b393a1-67ea-4c61-9d42-7860f2a0dff9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5b393a1-67ea-4c61-9d42-7860f2a0dff9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5b393a1-67ea-4c61-9d42-7860f2a0dff9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KorNLUdataset 다운\n",
        "!git clone https://github.com/kakaobrain/KorNLUDatasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB7o8B4KH9YL",
        "outputId": "fc5e7ca6-f830-43bb-9079-27b01e41e9b3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'KorNLUDatasets' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question pair 다운\n",
        "!git clone https://github.com/songys/Question_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBu2Y_aLO1ZO",
        "outputId": "12390b54-552c-4874-9615-6fbcff116010"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Question_pair' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/NLP/KorNLUDatasets/KorSTS/sts-train.tsv'"
      ],
      "metadata": {
        "id": "XbImLdmqIUFr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(path, sep=\"\\t+\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv3nsu9_IjvZ",
        "outputId": "028e860f-24c1-470b-9a2a-b9a323de301e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스코어로 되어있는 형태\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UnSeVUs_OYuD",
        "outputId": "23f6480b-746f-40cf-c38b-ceb2cef0e63e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              genre   filename      year    id  score  \\\n",
              "0     main-captions     MSRvid  2012test     1   5.00   \n",
              "1     main-captions     MSRvid  2012test     4   3.80   \n",
              "2     main-captions     MSRvid  2012test     5   3.80   \n",
              "3     main-captions     MSRvid  2012test     6   2.60   \n",
              "4     main-captions     MSRvid  2012test     9   4.25   \n",
              "...             ...        ...       ...   ...    ...   \n",
              "5744      main-news  headlines      2016  1456   0.00   \n",
              "5745      main-news  headlines      2016  1465   0.00   \n",
              "5746      main-news  headlines      2016  1466   0.00   \n",
              "5747      main-news  headlines      2016  1470   0.00   \n",
              "5748      main-news  headlines      2016  1492   0.00   \n",
              "\n",
              "                                    sentence1  \\\n",
              "0                               비행기가 이륙하고 있다.   \n",
              "1                       한 남자가 큰 플루트를 연주하고 있다.   \n",
              "2                      한 남자가 피자에 치즈를 뿌려놓고 있다.   \n",
              "3                            세 남자가 체스를 하고 있다.   \n",
              "4                          한 남자가 첼로를 연주하고 있다.   \n",
              "...                                       ...   \n",
              "5744                폭풍우 클로다흐가 영국을 강타하면서 심한 강풍   \n",
              "5745  리비아 테러리스트들이 공습에 대한 복수로 찍은 수십 명의 이집트 인질들   \n",
              "5746                            바레인으로 향하는 대통령   \n",
              "5747              중국, 인도는 양국 관계를 증진시키겠다고 맹세한다   \n",
              "5748           푸틴 대변인 : 도핑 혐의는 근거 없는 것으로 보인다.   \n",
              "\n",
              "                                           sentence2  \n",
              "0                                      비행기가 이륙하고 있다.  \n",
              "1                                  남자가 플루트를 연주하고 있다.  \n",
              "2                       한 남자가 구운 피자에 치즈 조각을 뿌려놓고 있다.  \n",
              "3                                   두 남자가 체스를 하고 있다.  \n",
              "4                            자리에 앉은 남자가 첼로를 연주하고 있다.  \n",
              "...                                              ...  \n",
              "5744                        메르켈은 나토와 라트비아의 연대를 약속한다.  \n",
              "5745  나일강에서 더 많은 시체가 발견되면서 이집트 보트 충돌 사고 사망자 수가 증가한다.  \n",
              "5746                      시 주석 : 에볼라 퇴치를 계속 돕기 위한 중국  \n",
              "5747             중국은 불안한 주식 거래자들을 안심시키기 위해 뒤뚱거리고 있다.  \n",
              "5748               가장 최근의 심한 날씨 : 토네이도 후 텍사스에서 1명 사망  \n",
              "\n",
              "[5749 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c4087db-f005-42e6-9265-9a45cc6433af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>filename</th>\n",
              "      <th>year</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>1</td>\n",
              "      <td>5.00</td>\n",
              "      <td>비행기가 이륙하고 있다.</td>\n",
              "      <td>비행기가 이륙하고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>4</td>\n",
              "      <td>3.80</td>\n",
              "      <td>한 남자가 큰 플루트를 연주하고 있다.</td>\n",
              "      <td>남자가 플루트를 연주하고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>5</td>\n",
              "      <td>3.80</td>\n",
              "      <td>한 남자가 피자에 치즈를 뿌려놓고 있다.</td>\n",
              "      <td>한 남자가 구운 피자에 치즈 조각을 뿌려놓고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>6</td>\n",
              "      <td>2.60</td>\n",
              "      <td>세 남자가 체스를 하고 있다.</td>\n",
              "      <td>두 남자가 체스를 하고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>9</td>\n",
              "      <td>4.25</td>\n",
              "      <td>한 남자가 첼로를 연주하고 있다.</td>\n",
              "      <td>자리에 앉은 남자가 첼로를 연주하고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5744</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1456</td>\n",
              "      <td>0.00</td>\n",
              "      <td>폭풍우 클로다흐가 영국을 강타하면서 심한 강풍</td>\n",
              "      <td>메르켈은 나토와 라트비아의 연대를 약속한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5745</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1465</td>\n",
              "      <td>0.00</td>\n",
              "      <td>리비아 테러리스트들이 공습에 대한 복수로 찍은 수십 명의 이집트 인질들</td>\n",
              "      <td>나일강에서 더 많은 시체가 발견되면서 이집트 보트 충돌 사고 사망자 수가 증가한다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5746</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1466</td>\n",
              "      <td>0.00</td>\n",
              "      <td>바레인으로 향하는 대통령</td>\n",
              "      <td>시 주석 : 에볼라 퇴치를 계속 돕기 위한 중국</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5747</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1470</td>\n",
              "      <td>0.00</td>\n",
              "      <td>중국, 인도는 양국 관계를 증진시키겠다고 맹세한다</td>\n",
              "      <td>중국은 불안한 주식 거래자들을 안심시키기 위해 뒤뚱거리고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5748</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2016</td>\n",
              "      <td>1492</td>\n",
              "      <td>0.00</td>\n",
              "      <td>푸틴 대변인 : 도핑 혐의는 근거 없는 것으로 보인다.</td>\n",
              "      <td>가장 최근의 심한 날씨 : 토네이도 후 텍사스에서 1명 사망</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5749 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c4087db-f005-42e6-9265-9a45cc6433af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c4087db-f005-42e6-9265-9a45cc6433af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c4087db-f005-42e6-9265-9a45cc6433af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복값 확인\n",
        "df2.duplicated(['sentence1', 'sentence2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE-JO84Pg_M0",
        "outputId": "4fd981c7-f6fd-483c-85f2-29c84f728e92"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복값 제거\n",
        "df2 = df2.drop_duplicates(['sentence1','sentence2'], keep='first', ignore_index=True)"
      ],
      "metadata": {
        "id": "9kXFbf7uhCB2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "df2.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BP4yZsghJgA",
        "outputId": "79e76894-f251-415d-afae-3473de48860a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genre        0\n",
              "filename     0\n",
              "year         0\n",
              "id           0\n",
              "score        0\n",
              "sentence1    0\n",
              "sentence2    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위와 같이 스코어 3 미만은 0 3 이상은 1 로 분류\n",
        "df2['binary-label'] = df2['score'].apply(lambda x: 0 if x < 3  else  1)"
      ],
      "metadata": {
        "id": "dMxcvtCabvGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f2368b-7b21-4d51-82b0-ee85c1025b8c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스코어 확인\n",
        "la11 = len(df2.loc[(df2['score'] >= 0) & (df2['score'] < 3.0)])\n",
        "la11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MejXxh55cUXN",
        "outputId": "a4299497-811c-475d-e7c1-196e854229fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2729"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 확인\n",
        "df2['binary-label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wauiuFJfcyep",
        "outputId": "07829698-5db0-4fe6-e592-ab03fd0ce0b4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2971\n",
              "0    2729\n",
              "Name: binary-label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_1 = df2[['sentence1', 'sentence2', 'binary-label']]\n",
        "df2_1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ypDIyweDdB9m",
        "outputId": "f47c7794-9bcf-4755-fe4c-50fb1cbc6165"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                sentence1                     sentence2  binary-label\n",
              "0           비행기가 이륙하고 있다.                 비행기가 이륙하고 있다.             1\n",
              "1   한 남자가 큰 플루트를 연주하고 있다.             남자가 플루트를 연주하고 있다.             1\n",
              "2  한 남자가 피자에 치즈를 뿌려놓고 있다.  한 남자가 구운 피자에 치즈 조각을 뿌려놓고 있다.             1\n",
              "3        세 남자가 체스를 하고 있다.              두 남자가 체스를 하고 있다.             0\n",
              "4      한 남자가 첼로를 연주하고 있다.       자리에 앉은 남자가 첼로를 연주하고 있다.             1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8e6ce92-2fdd-4932-8e68-8530596d40e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>binary-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>비행기가 이륙하고 있다.</td>\n",
              "      <td>비행기가 이륙하고 있다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>한 남자가 큰 플루트를 연주하고 있다.</td>\n",
              "      <td>남자가 플루트를 연주하고 있다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>한 남자가 피자에 치즈를 뿌려놓고 있다.</td>\n",
              "      <td>한 남자가 구운 피자에 치즈 조각을 뿌려놓고 있다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>세 남자가 체스를 하고 있다.</td>\n",
              "      <td>두 남자가 체스를 하고 있다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>한 남자가 첼로를 연주하고 있다.</td>\n",
              "      <td>자리에 앉은 남자가 첼로를 연주하고 있다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8e6ce92-2fdd-4932-8e68-8530596d40e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8e6ce92-2fdd-4932-8e68-8530596d40e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8e6ce92-2fdd-4932-8e68-8530596d40e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path2 = '/content/drive/MyDrive/NLP/Question_pair/kor_pair_train.csv'"
      ],
      "metadata": {
        "id": "Iu3nhnnYPsdj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv(path2)"
      ],
      "metadata": {
        "id": "kV0nfY9qP3c7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1이 다른문장 2가 같은문장\n",
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "em7V9YLSP7kb",
        "outputId": "caee8d47-e8a1-402d-836d-0e692792a467"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id   qid1   qid2                    question1  \\\n",
              "0        1      1      2            1000일 만난 여자친구와 이별   \n",
              "1        2      3      4         10년 연애사 되돌아보니 다 부질없네   \n",
              "2        3      5      6                  10년만나다 헤어지네   \n",
              "3        4      7      8       10월의 마지막밤 . 더 보고싶네 그사람   \n",
              "4        5      9     10                14년의 기나긴 이야기.   \n",
              "...    ...    ...    ...                          ...   \n",
              "6883  6884  13767  13768                O형 남자와 썸을 타는데   \n",
              "6884  6885  13769  13770                      SD카드 안돼   \n",
              "6885  6886  13771  13772               SNS 를 끊어야 하는데.   \n",
              "6886  6887  13773  13774            SNS 시간낭비인데 자꾸 보게됨   \n",
              "6887  6888  13775  13776  sns에서 다른 이성이랑 대화하는걸 보니 화가 나   \n",
              "\n",
              "                    question2  is_duplicate  \n",
              "0                    10년 연예의끝             1  \n",
              "1        10년이라는 시간이 참 무색하다 싶네             1  \n",
              "2               14년된 여자친구랑 이별             1  \n",
              "3                      15년…안녕             1  \n",
              "4            1년 9개월 의 연애 종지부.             1  \n",
              "...                       ...           ...  \n",
              "6883            O형 여자와 썸을 타는데             1  \n",
              "6884                SD카드 망가졌어             0  \n",
              "6885                 가슴 아픈 이별             1  \n",
              "6886  SNS 시간낭비인 거 아는데 매일 하는 중             0  \n",
              "6887            가슴에 구멍이 너무 커.             1  \n",
              "\n",
              "[6888 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-081ed0cd-a437-48e2-bdcb-862dc0f282b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1000일 만난 여자친구와 이별</td>\n",
              "      <td>10년 연예의끝</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>10년 연애사 되돌아보니 다 부질없네</td>\n",
              "      <td>10년이라는 시간이 참 무색하다 싶네</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>10년만나다 헤어지네</td>\n",
              "      <td>14년된 여자친구랑 이별</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>10월의 마지막밤 . 더 보고싶네 그사람</td>\n",
              "      <td>15년…안녕</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>14년의 기나긴 이야기.</td>\n",
              "      <td>1년 9개월 의 연애 종지부.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6883</th>\n",
              "      <td>6884</td>\n",
              "      <td>13767</td>\n",
              "      <td>13768</td>\n",
              "      <td>O형 남자와 썸을 타는데</td>\n",
              "      <td>O형 여자와 썸을 타는데</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6884</th>\n",
              "      <td>6885</td>\n",
              "      <td>13769</td>\n",
              "      <td>13770</td>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6885</th>\n",
              "      <td>6886</td>\n",
              "      <td>13771</td>\n",
              "      <td>13772</td>\n",
              "      <td>SNS 를 끊어야 하는데.</td>\n",
              "      <td>가슴 아픈 이별</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6886</th>\n",
              "      <td>6887</td>\n",
              "      <td>13773</td>\n",
              "      <td>13774</td>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6887</th>\n",
              "      <td>6888</td>\n",
              "      <td>13775</td>\n",
              "      <td>13776</td>\n",
              "      <td>sns에서 다른 이성이랑 대화하는걸 보니 화가 나</td>\n",
              "      <td>가슴에 구멍이 너무 커.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6888 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-081ed0cd-a437-48e2-bdcb-862dc0f282b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-081ed0cd-a437-48e2-bdcb-862dc0f282b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-081ed0cd-a437-48e2-bdcb-862dc0f282b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복값 확인\n",
        "df3.duplicated(['question1', 'question2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEpdc_Q3hZmU",
        "outputId": "4e75aa51-6115-4bea-a507-e77357c0faaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복값 제거\n",
        "df3 = df3.drop_duplicates(['question1', 'question2'], keep='first', ignore_index=True)"
      ],
      "metadata": {
        "id": "7M1dsWyKhf69"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "df3.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wSoYitfhn-Q",
        "outputId": "55734013-3310-4567-b8ea-9e25da42bdfe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id              0\n",
              "qid1            0\n",
              "qid2            0\n",
              "question1       0\n",
              "question2       0\n",
              "is_duplicate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 기준 바꾸기\n",
        "df3['binary-label'] = df3['is_duplicate'].apply(lambda x: 0 if x > 0 else 1)"
      ],
      "metadata": {
        "id": "7UZd7yDYdUKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706469f3-8b31-4fab-8671-56ce964b482b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 확인\n",
        "df3['is_duplicate'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lo7fAM7deVq",
        "outputId": "e2bad39f-a3eb-4368-95ee-103780e4bb94"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4749\n",
              "1    2138\n",
              "Name: is_duplicate, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 확인\n",
        "df3['binary-label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4wKCOWdv3q",
        "outputId": "990e2816-6223-41fd-be5f-106e3282144a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4749\n",
              "0    2138\n",
              "Name: binary-label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3_1 = df3[['question1', 'question2', 'binary-label']]"
      ],
      "metadata": {
        "id": "ex_inaHSdvyC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3_1.rename(columns = {'question1':'sentence1','question2':'sentence2'},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZux48BRhw4t",
        "outputId": "12c308ce-f82a-4bf0-bdb7-64c6a2f3c0cf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df1_1,df2_1, df3_1],axis=0, join='inner', ignore_index=True) "
      ],
      "metadata": {
        "id": "l1uGYEmyiESW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "EgRg30rdigJ7",
        "outputId": "f9bcc586-012c-4cad-e2e2-903445bdb54d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence1  \\\n",
              "0                       숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.   \n",
              "1          위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.   \n",
              "2                회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.   \n",
              "3      긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...   \n",
              "4                            호스트의 답장이 늦으나, 개선될 것으로 보입니다.   \n",
              "...                                                  ...   \n",
              "24243                                      O형 남자와 썸을 타는데   \n",
              "24244                                            SD카드 안돼   \n",
              "24245                                     SNS 를 끊어야 하는데.   \n",
              "24246                                  SNS 시간낭비인데 자꾸 보게됨   \n",
              "24247                        sns에서 다른 이성이랑 대화하는걸 보니 화가 나   \n",
              "\n",
              "                                        sentence2  binary-label  \n",
              "0      숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.             1  \n",
              "1           시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.             0  \n",
              "2                      사람들이 주로 네이버 메일을 쓰는 이유를 알려줘             0  \n",
              "3       고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.             0  \n",
              "4                      호스트 응답이 늦었지만 개선될 것으로 보입니다.             1  \n",
              "...                                           ...           ...  \n",
              "24243                               O형 여자와 썸을 타는데             0  \n",
              "24244                                   SD카드 망가졌어             1  \n",
              "24245                                    가슴 아픈 이별             0  \n",
              "24246                     SNS 시간낭비인 거 아는데 매일 하는 중             1  \n",
              "24247                               가슴에 구멍이 너무 커.             0  \n",
              "\n",
              "[24248 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dc37921-1720-45a9-8438-f9e241535513\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>binary-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.</td>\n",
              "      <td>숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다.</td>\n",
              "      <td>시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘.</td>\n",
              "      <td>사람들이 주로 네이버 메일을 쓰는 이유를 알려줘</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업...</td>\n",
              "      <td>고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호스트의 답장이 늦으나, 개선될 것으로 보입니다.</td>\n",
              "      <td>호스트 응답이 늦었지만 개선될 것으로 보입니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24243</th>\n",
              "      <td>O형 남자와 썸을 타는데</td>\n",
              "      <td>O형 여자와 썸을 타는데</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24244</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24245</th>\n",
              "      <td>SNS 를 끊어야 하는데.</td>\n",
              "      <td>가슴 아픈 이별</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24246</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24247</th>\n",
              "      <td>sns에서 다른 이성이랑 대화하는걸 보니 화가 나</td>\n",
              "      <td>가슴에 구멍이 너무 커.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24248 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dc37921-1720-45a9-8438-f9e241535513')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1dc37921-1720-45a9-8438-f9e241535513 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1dc37921-1720-45a9-8438-f9e241535513');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleansing(text):\n",
        "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ·!』\\\\‘〈〉|\\(\\)\\[\\]\\<\\>`\\'…》《]','', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "Vf3X5FKCUOjr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean1'] = df['sentence1'].apply(cleansing)\n",
        "df['clean2'] = df['sentence2'].apply(cleansing)"
      ],
      "metadata": {
        "id": "oVIYADW5URMr"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= df[['clean1', 'clean2', 'binary-label']]"
      ],
      "metadata": {
        "id": "pilYokyU1GSG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {'clean1':'sentence1','clean2':'sentence2'},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSz-1SOP1BMl",
        "outputId": "7b435179-1b93-471b-d7eb-5feccb6ed873"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "YM2v67f85S_o",
        "outputId": "032086a9-6f16-45c5-eca2-b6304af82461"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      guid          source  \\\n",
              "0    klue-sts-v1_dev_00000      airbnb-rtt   \n",
              "1    klue-sts-v1_dev_00001  airbnb-sampled   \n",
              "2    klue-sts-v1_dev_00002  policy-sampled   \n",
              "3    klue-sts-v1_dev_00003      airbnb-rtt   \n",
              "4    klue-sts-v1_dev_00004    paraKQC-para   \n",
              "..                     ...             ...   \n",
              "514  klue-sts-v1_dev_00514      policy-rtt   \n",
              "515  klue-sts-v1_dev_00515  airbnb-sampled   \n",
              "516  klue-sts-v1_dev_00516  airbnb-sampled   \n",
              "517  klue-sts-v1_dev_00517  policy-sampled   \n",
              "518  klue-sts-v1_dev_00518  airbnb-sampled   \n",
              "\n",
              "                                             sentence1  \\\n",
              "0                             무엇보다도 호스트분들이 너무 친절하셨습니다.   \n",
              "1                               주요 관광지 모두 걸어서 이동가능합니다.   \n",
              "2    학생들의 균형 있는 영어능력을 향상시킬 수 있는 학교 수업을 유도하기 위해 2018...   \n",
              "3                            다만, 도로와 인접해서 거리의 소음이 들려요.   \n",
              "4                  형이 다시 캐나다 들어가야 하니 가족모임 일정은 바꾸지 마세요.   \n",
              "..                                                 ...   \n",
              "514    문체부는 이를 연차적으로 확대, 시행해 학교운동부와 스포츠클럽 간의 연계를 강화한다.   \n",
              "515                        일단 정확한 정보와 빠른 답변이 정말 좋았습니다.   \n",
              "516                         게스트에 대한 배려가 묻어나는 시설들이었습니다.   \n",
              "517                         밤하늘을 배경으로 ‘비대면 드론쇼’도 펼쳐진다.   \n",
              "518                      여느 포르투갈의 비앤비와 같이 엘리베이터는 없습니다.   \n",
              "\n",
              "                                             sentence2  \\\n",
              "0                              무엇보다도, 호스트들은 매우 친절했습니다.   \n",
              "1                          위치는 피렌체 중심가까지 걸어서 이동 가능합니다.   \n",
              "2    영어 영역의 경우 학생들이 한글 해석본을 암기하는 문제를 해소하기 위해 2016학년...   \n",
              "3                   하지만, 길과 가깝기 때문에 거리의 소음을 들을 수 있습니다.   \n",
              "4                              가족 모임 일정은 바꾸지 말도록 하십시오.   \n",
              "..                                                 ...   \n",
              "514  문화체육관광부는 학교스포츠학과와 스포츠클럽의 연계성을 강화하기 위해 매년 이 프로그...   \n",
              "515                      호스트의 빠른 답변과 유용한 정보들이 정말 좋습니다.   \n",
              "516                         우선 공간에 대한 센스가 돋보이는 곳이었습니다.   \n",
              "517                            ‘비대면 실감형 문화공연 플랫폼’ 개념도.   \n",
              "518                     포르투의 거의 모든 숙박 시설은 엘리베이터는 없습니다.   \n",
              "\n",
              "                                                labels  \\\n",
              "0    {'label': 4.9, 'real-label': 4.857142857142857...   \n",
              "1    {'label': 1.4, 'real-label': 1.428571428571429...   \n",
              "2    {'label': 1.3, 'real-label': 1.285714285714286...   \n",
              "3    {'label': 3.7, 'real-label': 3.714285714285714...   \n",
              "4    {'label': 2.5, 'real-label': 2.5, 'binary-labe...   \n",
              "..                                                 ...   \n",
              "514  {'label': 2.2, 'real-label': 2.2, 'binary-labe...   \n",
              "515  {'label': 2.8, 'real-label': 2.833333333333333...   \n",
              "516  {'label': 0.30000000000000004, 'real-label': 0...   \n",
              "517  {'label': 0.30000000000000004, 'real-label': 0...   \n",
              "518  {'label': 2.9, 'real-label': 2.857142857142857...   \n",
              "\n",
              "                                           annotations  \n",
              "0    {'agreement': '0:0:0:0:1:6', 'annotators': ['1...  \n",
              "1    {'agreement': '0:4:3:0:0:0', 'annotators': ['1...  \n",
              "2    {'agreement': '0:5:2:0:0:0', 'annotators': ['0...  \n",
              "3    {'agreement': '0:0:0:2:5:0', 'annotators': ['1...  \n",
              "4    {'agreement': '1:0:1:3:1:0', 'annotators': ['0...  \n",
              "..                                                 ...  \n",
              "514  {'agreement': '0:1:2:2:0:0', 'annotators': ['0...  \n",
              "515  {'agreement': '0:0:1:5:0:0', 'annotators': ['0...  \n",
              "516  {'agreement': '4:2:0:0:0:0', 'annotators': ['1...  \n",
              "517  {'agreement': '5:0:1:0:0:0', 'annotators': ['0...  \n",
              "518  {'agreement': '0:0:2:4:1:0', 'annotators': ['0...  \n",
              "\n",
              "[519 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5447fd63-3bb1-433d-85b2-1f65b642721f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>source</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>labels</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>klue-sts-v1_dev_00000</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>무엇보다도 호스트분들이 너무 친절하셨습니다.</td>\n",
              "      <td>무엇보다도, 호스트들은 매우 친절했습니다.</td>\n",
              "      <td>{'label': 4.9, 'real-label': 4.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:0:0:1:6', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>klue-sts-v1_dev_00001</td>\n",
              "      <td>airbnb-sampled</td>\n",
              "      <td>주요 관광지 모두 걸어서 이동가능합니다.</td>\n",
              "      <td>위치는 피렌체 중심가까지 걸어서 이동 가능합니다.</td>\n",
              "      <td>{'label': 1.4, 'real-label': 1.428571428571429...</td>\n",
              "      <td>{'agreement': '0:4:3:0:0:0', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>klue-sts-v1_dev_00002</td>\n",
              "      <td>policy-sampled</td>\n",
              "      <td>학생들의 균형 있는 영어능력을 향상시킬 수 있는 학교 수업을 유도하기 위해 2018...</td>\n",
              "      <td>영어 영역의 경우 학생들이 한글 해석본을 암기하는 문제를 해소하기 위해 2016학년...</td>\n",
              "      <td>{'label': 1.3, 'real-label': 1.285714285714286...</td>\n",
              "      <td>{'agreement': '0:5:2:0:0:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>klue-sts-v1_dev_00003</td>\n",
              "      <td>airbnb-rtt</td>\n",
              "      <td>다만, 도로와 인접해서 거리의 소음이 들려요.</td>\n",
              "      <td>하지만, 길과 가깝기 때문에 거리의 소음을 들을 수 있습니다.</td>\n",
              "      <td>{'label': 3.7, 'real-label': 3.714285714285714...</td>\n",
              "      <td>{'agreement': '0:0:0:2:5:0', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>klue-sts-v1_dev_00004</td>\n",
              "      <td>paraKQC-para</td>\n",
              "      <td>형이 다시 캐나다 들어가야 하니 가족모임 일정은 바꾸지 마세요.</td>\n",
              "      <td>가족 모임 일정은 바꾸지 말도록 하십시오.</td>\n",
              "      <td>{'label': 2.5, 'real-label': 2.5, 'binary-labe...</td>\n",
              "      <td>{'agreement': '1:0:1:3:1:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>klue-sts-v1_dev_00514</td>\n",
              "      <td>policy-rtt</td>\n",
              "      <td>문체부는 이를 연차적으로 확대, 시행해 학교운동부와 스포츠클럽 간의 연계를 강화한다.</td>\n",
              "      <td>문화체육관광부는 학교스포츠학과와 스포츠클럽의 연계성을 강화하기 위해 매년 이 프로그...</td>\n",
              "      <td>{'label': 2.2, 'real-label': 2.2, 'binary-labe...</td>\n",
              "      <td>{'agreement': '0:1:2:2:0:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>klue-sts-v1_dev_00515</td>\n",
              "      <td>airbnb-sampled</td>\n",
              "      <td>일단 정확한 정보와 빠른 답변이 정말 좋았습니다.</td>\n",
              "      <td>호스트의 빠른 답변과 유용한 정보들이 정말 좋습니다.</td>\n",
              "      <td>{'label': 2.8, 'real-label': 2.833333333333333...</td>\n",
              "      <td>{'agreement': '0:0:1:5:0:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>klue-sts-v1_dev_00516</td>\n",
              "      <td>airbnb-sampled</td>\n",
              "      <td>게스트에 대한 배려가 묻어나는 시설들이었습니다.</td>\n",
              "      <td>우선 공간에 대한 센스가 돋보이는 곳이었습니다.</td>\n",
              "      <td>{'label': 0.30000000000000004, 'real-label': 0...</td>\n",
              "      <td>{'agreement': '4:2:0:0:0:0', 'annotators': ['1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>klue-sts-v1_dev_00517</td>\n",
              "      <td>policy-sampled</td>\n",
              "      <td>밤하늘을 배경으로 ‘비대면 드론쇼’도 펼쳐진다.</td>\n",
              "      <td>‘비대면 실감형 문화공연 플랫폼’ 개념도.</td>\n",
              "      <td>{'label': 0.30000000000000004, 'real-label': 0...</td>\n",
              "      <td>{'agreement': '5:0:1:0:0:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>klue-sts-v1_dev_00518</td>\n",
              "      <td>airbnb-sampled</td>\n",
              "      <td>여느 포르투갈의 비앤비와 같이 엘리베이터는 없습니다.</td>\n",
              "      <td>포르투의 거의 모든 숙박 시설은 엘리베이터는 없습니다.</td>\n",
              "      <td>{'label': 2.9, 'real-label': 2.857142857142857...</td>\n",
              "      <td>{'agreement': '0:0:2:4:1:0', 'annotators': ['0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>519 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5447fd63-3bb1-433d-85b2-1f65b642721f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5447fd63-3bb1-433d-85b2-1f65b642721f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5447fd63-3bb1-433d-85b2-1f65b642721f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.duplicated(['sentence1', 'sentence2']).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldtX_gFN5cBM",
        "outputId": "4ea964da-81d8-4a0f-adbc-f77f79cdd4a8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcsj4wk55eRK",
        "outputId": "9021c105-39bd-4e70-af58-4231d02c389b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "guid           0\n",
              "source         0\n",
              "sentence1      0\n",
              "sentence2      0\n",
              "labels         0\n",
              "annotations    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 분리\n",
        "labels2 = test.labels.to_list()\n",
        "labels2 = pd.DataFrame(labels2)\n",
        "print(len(labels2))\n",
        "labels2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "ou5cw6QA5iEi",
        "outputId": "7ee6bd60-b5ea-46fe-ec2b-38159903a0fb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "519\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label  real-label  binary-label\n",
              "0      4.9    4.857143             1\n",
              "1      1.4    1.428571             0\n",
              "2      1.3    1.285714             0\n",
              "3      3.7    3.714286             1\n",
              "4      2.5    2.500000             0\n",
              "..     ...         ...           ...\n",
              "514    2.2    2.200000             0\n",
              "515    2.8    2.833333             0\n",
              "516    0.3    0.333333             0\n",
              "517    0.3    0.333333             0\n",
              "518    2.9    2.857143             0\n",
              "\n",
              "[519 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33f4ba4a-b2fd-4ec3-a68f-a20d6e6baf50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>real-label</th>\n",
              "      <th>binary-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.9</td>\n",
              "      <td>4.857143</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.4</td>\n",
              "      <td>1.428571</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.3</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.7</td>\n",
              "      <td>3.714286</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>2.2</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>2.8</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>2.9</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>519 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33f4ba4a-b2fd-4ec3-a68f-a20d6e6baf50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33f4ba4a-b2fd-4ec3-a68f-a20d6e6baf50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33f4ba4a-b2fd-4ec3-a68f-a20d6e6baf50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = test[['sentence1', 'sentence2']].join(labels2['binary-label'])\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RxvECX8j5y8v",
        "outputId": "e7e7c6c5-54f0-46cd-971f-0e66ea7f8514"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             sentence1  \\\n",
              "0                             무엇보다도 호스트분들이 너무 친절하셨습니다.   \n",
              "1                               주요 관광지 모두 걸어서 이동가능합니다.   \n",
              "2    학생들의 균형 있는 영어능력을 향상시킬 수 있는 학교 수업을 유도하기 위해 2018...   \n",
              "3                            다만, 도로와 인접해서 거리의 소음이 들려요.   \n",
              "4                  형이 다시 캐나다 들어가야 하니 가족모임 일정은 바꾸지 마세요.   \n",
              "..                                                 ...   \n",
              "514    문체부는 이를 연차적으로 확대, 시행해 학교운동부와 스포츠클럽 간의 연계를 강화한다.   \n",
              "515                        일단 정확한 정보와 빠른 답변이 정말 좋았습니다.   \n",
              "516                         게스트에 대한 배려가 묻어나는 시설들이었습니다.   \n",
              "517                         밤하늘을 배경으로 ‘비대면 드론쇼’도 펼쳐진다.   \n",
              "518                      여느 포르투갈의 비앤비와 같이 엘리베이터는 없습니다.   \n",
              "\n",
              "                                             sentence2  binary-label  \n",
              "0                              무엇보다도, 호스트들은 매우 친절했습니다.             1  \n",
              "1                          위치는 피렌체 중심가까지 걸어서 이동 가능합니다.             0  \n",
              "2    영어 영역의 경우 학생들이 한글 해석본을 암기하는 문제를 해소하기 위해 2016학년...             0  \n",
              "3                   하지만, 길과 가깝기 때문에 거리의 소음을 들을 수 있습니다.             1  \n",
              "4                              가족 모임 일정은 바꾸지 말도록 하십시오.             0  \n",
              "..                                                 ...           ...  \n",
              "514  문화체육관광부는 학교스포츠학과와 스포츠클럽의 연계성을 강화하기 위해 매년 이 프로그...             0  \n",
              "515                      호스트의 빠른 답변과 유용한 정보들이 정말 좋습니다.             0  \n",
              "516                         우선 공간에 대한 센스가 돋보이는 곳이었습니다.             0  \n",
              "517                            ‘비대면 실감형 문화공연 플랫폼’ 개념도.             0  \n",
              "518                     포르투의 거의 모든 숙박 시설은 엘리베이터는 없습니다.             0  \n",
              "\n",
              "[519 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fee37436-db30-468a-8b0b-961099133407\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>binary-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>무엇보다도 호스트분들이 너무 친절하셨습니다.</td>\n",
              "      <td>무엇보다도, 호스트들은 매우 친절했습니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>주요 관광지 모두 걸어서 이동가능합니다.</td>\n",
              "      <td>위치는 피렌체 중심가까지 걸어서 이동 가능합니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>학생들의 균형 있는 영어능력을 향상시킬 수 있는 학교 수업을 유도하기 위해 2018...</td>\n",
              "      <td>영어 영역의 경우 학생들이 한글 해석본을 암기하는 문제를 해소하기 위해 2016학년...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>다만, 도로와 인접해서 거리의 소음이 들려요.</td>\n",
              "      <td>하지만, 길과 가깝기 때문에 거리의 소음을 들을 수 있습니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>형이 다시 캐나다 들어가야 하니 가족모임 일정은 바꾸지 마세요.</td>\n",
              "      <td>가족 모임 일정은 바꾸지 말도록 하십시오.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>문체부는 이를 연차적으로 확대, 시행해 학교운동부와 스포츠클럽 간의 연계를 강화한다.</td>\n",
              "      <td>문화체육관광부는 학교스포츠학과와 스포츠클럽의 연계성을 강화하기 위해 매년 이 프로그...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>일단 정확한 정보와 빠른 답변이 정말 좋았습니다.</td>\n",
              "      <td>호스트의 빠른 답변과 유용한 정보들이 정말 좋습니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>게스트에 대한 배려가 묻어나는 시설들이었습니다.</td>\n",
              "      <td>우선 공간에 대한 센스가 돋보이는 곳이었습니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>밤하늘을 배경으로 ‘비대면 드론쇼’도 펼쳐진다.</td>\n",
              "      <td>‘비대면 실감형 문화공연 플랫폼’ 개념도.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>여느 포르투갈의 비앤비와 같이 엘리베이터는 없습니다.</td>\n",
              "      <td>포르투의 거의 모든 숙박 시설은 엘리베이터는 없습니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>519 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fee37436-db30-468a-8b0b-961099133407')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fee37436-db30-468a-8b0b-961099133407 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fee37436-db30-468a-8b0b-961099133407');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "        print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    return device\n",
        "device = set_device()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaP2ngFceZrq",
        "outputId": "fbbeac0d-fa89-4c6a-9877-3caaed39839a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "t-c0aGxdkSki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cd1385-fb4f-4c6b-8639-39e9b7fd5230"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.19.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, RobertaModel, RobertaTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8axs07kVqa7S"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "db83HLQJb4W9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(df, test_size=0.3, shuffle=True)"
      ],
      "metadata": {
        "id": "1qAd7pXTq5Zg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial"
      ],
      "metadata": {
        "id": "CgNWIzELYjje"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "ldpIWP9sSVnC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentence1, sentence2, real_label):\n",
        "        self.X1 = sentence1 #list str\n",
        "        self.X2 = sentence2 #list str\n",
        "        self.Y = real_label #list float\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X1[index], self.X2[index], self.Y[index]"
      ],
      "metadata": {
        "id": "skHAyUHKqa3D"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(df, flag):\n",
        "    sen_one = df['sentence1'].tolist()\n",
        "    sen_two = df['sentence2'].tolist()\n",
        "    real_lab = df['binary-label'].tolist()\n",
        "\n",
        "    return CustomDataset(sen_one, sen_two, real_lab)"
      ],
      "metadata": {
        "id": "5lU8zinhqmmp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = generate_dataset(train, True)\n",
        "val_dataset = generate_dataset(val, True)\n",
        "test_dataset = generate_dataset(test, True)"
      ],
      "metadata": {
        "id": "BTirkoVBqzNe"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"
      ],
      "metadata": {
        "id": "98XQ8pCWr1EB"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CustomCollateFn(batch):\n",
        "    sen_one_list = []\n",
        "    sen_two_list = []\n",
        "    label_list = []\n",
        "\n",
        "\n",
        "    for sen_one, sen_two, label in batch:\n",
        "        sen_one_list.append(sen_one)\n",
        "        sen_two_list.append(sen_two)\n",
        "        label_list.append(label)\n",
        "    \n",
        "    tokenized_sen_one = tokenizer(sen_one_list, add_special_tokens=True, padding='max_length',\n",
        "                                truncation=True, max_length=128, return_tensors='pt')\n",
        "    tokenized_sen_two = tokenizer(sen_two_list, add_special_tokens=True, padding='max_length',\n",
        "                                truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "    label_list = torch.Tensor(label_list)\n",
        "\n",
        "\n",
        "    return (tokenized_sen_one, tokenized_sen_two, label_list)"
      ],
      "metadata": {
        "id": "6mrlkb2rr6Cv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CustomCollateFn_dev(batch):\n",
        "    sen_one_list = []\n",
        "    sen_two_list = []\n",
        "    label_list = []\n",
        "\n",
        "\n",
        "    for sen_one, sen_two, label in batch:\n",
        "        sen_one_list.append(sen_one)\n",
        "        sen_two_list.append(sen_two)\n",
        "        label_list.append(label)\n",
        "\n",
        "    tokenized_sen_one = tokenizer(sen_one_list, add_special_tokens=True, padding='max_length',\n",
        "                                truncation=True, max_length=128, return_tensors='pt')\n",
        "    tokenized_sen_two = tokenizer(sen_two_list, add_special_tokens=True, padding='max_length',\n",
        "                                truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "    label_list = torch.Tensor(label_list)\n",
        "\n",
        "    return (tokenized_sen_one, tokenized_sen_two, label_list)"
      ],
      "metadata": {
        "id": "7QBxI3XCtQn4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling_fn(output, attention_mask):\n",
        "    embedding = output.last_hidden_state # (batch len, longest sentence length, 1024)\n",
        "    att_msk = attention_mask # (batch_len, 1024)\n",
        "    mask = att_msk.unsqueeze(-1).expand(output.last_hidden_state.size()).float() # (batch len, longest sentence length, 1024)\n",
        "    masked_embedding = output.last_hidden_state * mask # (batch_len, longest sen len, 1024)\n",
        "    me_sum = torch.sum(masked_embedding, 1) # (batch_len, 1024)\n",
        "    ms_sum = torch.clamp(mask.sum(1), min=1e-9) # (batch_len, 1024)\n",
        "    mean_pool = me_sum/ms_sum # batch_len, 1024\n",
        "    return mean_pool"
      ],
      "metadata": {
        "id": "WWATlyomsPIo"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomPooling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomPooling, self).__init__()\n",
        "\n",
        "        self.robert = AutoModel.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "\n",
        "        self.cos_score = nn.Sequential(\n",
        "            nn.Identity()\n",
        "        )\n",
        "    \n",
        "    def forward(self, senone, sentwo):\n",
        "        output_one = self.robert(input_ids=senone['input_ids'], attention_mask=senone['attention_mask'],\n",
        "                             token_type_ids=senone['token_type_ids'])\n",
        "        output_two = self.robert(input_ids=sentwo['input_ids'], attention_mask=sentwo['attention_mask'],\n",
        "                             token_type_ids=sentwo['token_type_ids'])\n",
        "\n",
        "        pooled_one = mean_pooling_fn(output_one, senone['attention_mask'])\n",
        "        pooled_two = mean_pooling_fn(output_two, sentwo['attention_mask'])\n",
        "\n",
        "\n",
        "        cos_sim = torch.cosine_similarity(pooled_one, pooled_two)\n",
        "        logit = self.cos_score(cos_sim)\n",
        "\n",
        "        return logit"
      ],
      "metadata": {
        "id": "C8EHFH7nsReR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initializer(input_dataloader, epochs):\n",
        "    model = CustomPooling()\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "    print(f'total step: {len(input_dataloader) * epochs}')\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps = round(len(input_dataloader)*0.1),\n",
        "        num_training_steps = len(input_dataloader) * epochs,\n",
        "\n",
        "    )\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "metadata": {
        "id": "ojy1czITsck4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'/content/drive/MyDrive/data/checkpoints/sts_vx.ckpt.{epoch}'\n",
        "    torch.save({\n",
        "        'epoch':epoch,\n",
        "        'model_state_dict':model.state_dict(),\n",
        "        'optimizer_state_dict':optimizer.state_dict(),\n",
        "        'scheduler_state_dict':scheduler.state_dict(),\n",
        "        'loss':loss\n",
        "    }, file_name)\n",
        "\n",
        "    print(f'SAVING EPOCH {epoch} ...')"
      ],
      "metadata": {
        "id": "zhkThrouslzF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loss_fct, scheduler, optimizer, train_dataloader, valid_dataloader, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f'****** STARTING TO TRAIN EPOCH #{epoch} ******')\n",
        "\n",
        "        total_loss = 0\n",
        "        batch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        model.train()\n",
        "        model.to(device)\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_count += 1\n",
        "            batch = tuple(items.to(device) for items in batch)\n",
        "\n",
        "            (x_batch_one, x_batch_two, y_batch) = batch\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            logit = model(x_batch_one, x_batch_two)\n",
        "            loss = loss_fct(logit, y_batch)\n",
        "\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            if(step % 10 == 0 and step != 0):\n",
        "\n",
        "                writer.add_scalar(\n",
        "                    tag = \"Train Loss\",\n",
        "                    scalar_value = batch_loss / batch_count,\n",
        "                    global_step = epoch * len(train_dataloader) + step\n",
        "                )\n",
        "\n",
        "                # 학습 learning rate 기록\n",
        "                writer.add_scalar(\n",
        "                    tag = \"Train LR\",\n",
        "                    scalar_value = optimizer.param_groups[0]['lr'],\n",
        "                    global_step = epoch * len(train_dataloader) + step\n",
        "                )\n",
        "\n",
        "                learning_rate = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                batch_loss, batch_count = 0,0\n",
        "\n",
        "        print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "        print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "\n",
        "        if valid_dataloader is not None:\n",
        "            print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "            valid_loss, valid_pearson, valid_f1 = validate(model, loss_fct, valid_dataloader)\n",
        "            print(f\"Epoch {epoch} Valid Loss : {valid_loss} Valid Pearsonr : {valid_pearson} ValidF1 : {valid_f1}\")\n",
        "            \n",
        "            writer.add_scalar(\n",
        "                tag = \"Valid Loss\",\n",
        "                scalar_value = valid_loss,\n",
        "                global_step = epoch\n",
        "            )\n",
        "\n",
        "            writer.add_scalar(\n",
        "                tag = \"Valid Pearsonr\",\n",
        "                scalar_value = valid_pearson,\n",
        "                global_step = epoch\n",
        "            )\n",
        "\n",
        "            writer.add_scalar(\n",
        "                tag = \"Valid F1\",\n",
        "                scalar_value = valid_f1,\n",
        "                global_step = epoch\n",
        "            )\n",
        "            \n",
        "            print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "        \n",
        "        save_checkpoint(\".\", model, optimizer, scheduler, epoch, total_loss/(step+1))\n",
        "        torch.cuda.empty_cache()\n",
        "    print('** Train Completed! **')"
      ],
      "metadata": {
        "id": "I77TwxPsspxG"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audtorch\n",
        "from audtorch.metrics.functional import pearsonr\n",
        "from sklearn.metrics import f1_score\n",
        "from scipy import stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXNYIPGlsuBt",
        "outputId": "290203f3-3ac5-4e8e-ef4e-44a297fdf454"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: audtorch in /usr/local/lib/python3.7/dist-packages (0.6.4)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from audtorch) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.3.5)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from audtorch) (0.8.1)\n",
            "Requirement already satisfied: audiofile in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from audtorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from audtorch) (0.8.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from audtorch) (4.64.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (2.1.9)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (1.0.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (0.10.3.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->audtorch) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->audtorch) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->audtorch) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.8.0->audtorch) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->audtorch) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->audtorch) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->audtorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->audtorch) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->audtorch) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->audtorch) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->audtorch) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.8.0->audtorch) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.8.0->audtorch) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.8.0->audtorch) (2.21)\n",
            "Requirement already satisfied: audeer in /usr/local/lib/python3.7/dist-packages (from audiofile->audtorch) (1.18.0)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.7/dist-packages (from audiofile->audtorch) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->audtorch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->audtorch) (2022.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->audtorch) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "!pip install jupyter-tensorboard\n",
        "\n",
        "writer = SummaryWriter('/content/drive/MyDrive/data/sts_logs/vx')\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8g8lwJQuaxK",
        "outputId": "7d8a5a8a-861e-4bdd-f5a7-ca28310c7bdc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jupyter-tensorboard in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: notebook>=5.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-tensorboard) (5.3.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (2.11.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (5.3.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=5.0->jupyter-tensorboard) (4.10.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (23.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=5.2.0->notebook>=5.0->jupyter-tensorboard) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=5.0->jupyter-tensorboard) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=5.0->jupyter-tensorboard) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=5.0->jupyter-tensorboard) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=5.0->jupyter-tensorboard) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=5.0->jupyter-tensorboard) (1.5.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=5.0->jupyter-tensorboard) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=5.0->jupyter-tensorboard) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=5.0->jupyter-tensorboard) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=5.0->jupyter-tensorboard) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir {\"/content/drive/MyDrive/data/sts_logs/v2\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "grtBXXjXuftW",
        "outputId": "9a723503-0849-4a45-dee1-935f5d5ebf65"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 593), started 5:23:10 ago. (Use '!kill 593' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loss_fct, valid_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    all_prediction = []\n",
        "    all_reallabel = []\n",
        "\n",
        "    for step, batch in enumerate(valid_dataloader):\n",
        "        batch = tuple(items.to(device) for items in batch)\n",
        "\n",
        "        (x_batch_one, x_batch_two, batch_y) = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logit = model(x_batch_one, x_batch_two)\n",
        "\n",
        "\n",
        "        loss = loss_fct(logit, batch_y)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "        logit = logit[:].cpu()\n",
        "        batch_y = batch_y.cpu()\n",
        "\n",
        "        print(f'Step: {step},  Pearson: {pearsonr(logit, batch_y)}')\n",
        "\n",
        "        all_prediction = all_prediction + logit.tolist()\n",
        "        all_reallabel = all_reallabel + batch_y.tolist()\n",
        "\n",
        "    #pearson\n",
        "\n",
        "    pred = torch.Tensor(all_prediction) # x\n",
        "    real = torch.Tensor(all_reallabel) # y\n",
        "    \n",
        "    pearson = pearsonr(pred, real)\n",
        "    \n",
        "    #loss\n",
        "    total_loss = total_loss / (step+1)\n",
        "\n",
        "    #f1\n",
        "    fone = f1_process(pred, real)\n",
        "\n",
        "    return total_loss, pearson, fone"
      ],
      "metadata": {
        "id": "ofd29hF1sz23"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_process(pred, real):\n",
        "    bin_real = []\n",
        "    bin_pred = []\n",
        "\n",
        "    for index in range(len(real)):\n",
        "        if real[index] < 1:\n",
        "            bin_real.append(0)\n",
        "        else:\n",
        "            bin_real.append(1)\n",
        "        if pred[index] < 1:\n",
        "            bin_pred.append(0)\n",
        "        else:\n",
        "            bin_pred.append(1)\n",
        "    return f1_score(bin_real, bin_pred)"
      ],
      "metadata": {
        "id": "MZpIUQmfs04L"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 16,\n",
        "    sampler = RandomSampler(train_dataset),\n",
        "    collate_fn = CustomCollateFn,\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = 32,\n",
        "    sampler = SequentialSampler(val_dataset),\n",
        "    collate_fn = CustomCollateFn_dev,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = 32,\n",
        "    sampler = SequentialSampler(test_dataset),\n",
        "    collate_fn = CustomCollateFn_dev,\n",
        ") "
      ],
      "metadata": {
        "id": "wwLNVI9Ws2tQ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "loss_fct = MSELoss()\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, loss_fct, scheduler, optimizer, train_dataloader, valid_dataloader, epochs)\n",
        "\n",
        "# validate(model, loss_fct, valid_dataloader, device)\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "zSkNmCxcNItU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45221c3-78ef-4532-b5f6-701b47d6019b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total step: 4244\n",
            "****** STARTING TO TRAIN EPOCH #0 ******\n",
            "Epoch: 0, Step : 10, LR : 1.037735849056604e-06, Avg Loss : 0.3538\n",
            "Epoch: 0, Step : 20, LR : 1.981132075471698e-06, Avg Loss : 0.3619\n",
            "Epoch: 0, Step : 30, LR : 2.9245283018867924e-06, Avg Loss : 0.3339\n",
            "Epoch: 0, Step : 40, LR : 3.8679245283018875e-06, Avg Loss : 0.2661\n",
            "Epoch: 0, Step : 50, LR : 4.811320754716982e-06, Avg Loss : 0.2137\n",
            "Epoch: 0, Step : 60, LR : 5.754716981132076e-06, Avg Loss : 0.1707\n",
            "Epoch: 0, Step : 70, LR : 6.69811320754717e-06, Avg Loss : 0.1384\n",
            "Epoch: 0, Step : 80, LR : 7.641509433962266e-06, Avg Loss : 0.1279\n",
            "Epoch: 0, Step : 90, LR : 8.58490566037736e-06, Avg Loss : 0.1433\n",
            "Epoch: 0, Step : 100, LR : 9.528301886792455e-06, Avg Loss : 0.1239\n",
            "Epoch: 0, Step : 110, LR : 9.9879168680522e-06, Avg Loss : 0.1214\n",
            "Epoch: 0, Step : 120, LR : 9.963750604156598e-06, Avg Loss : 0.1220\n",
            "Epoch: 0, Step : 130, LR : 9.939584340260995e-06, Avg Loss : 0.1113\n",
            "Epoch: 0, Step : 140, LR : 9.915418076365395e-06, Avg Loss : 0.1023\n",
            "Epoch: 0, Step : 150, LR : 9.891251812469794e-06, Avg Loss : 0.0945\n",
            "Epoch: 0, Step : 160, LR : 9.867085548574191e-06, Avg Loss : 0.1003\n",
            "Epoch: 0, Step : 170, LR : 9.842919284678589e-06, Avg Loss : 0.0855\n",
            "Epoch: 0, Step : 180, LR : 9.818753020782988e-06, Avg Loss : 0.1382\n",
            "Epoch: 0, Step : 190, LR : 9.794586756887387e-06, Avg Loss : 0.1124\n",
            "Epoch: 0, Step : 200, LR : 9.770420492991785e-06, Avg Loss : 0.1043\n",
            "Epoch: 0, Step : 210, LR : 9.746254229096182e-06, Avg Loss : 0.0910\n",
            "Epoch: 0, Step : 220, LR : 9.72208796520058e-06, Avg Loss : 0.1001\n",
            "Epoch: 0, Step : 230, LR : 9.697921701304979e-06, Avg Loss : 0.0965\n",
            "Epoch: 0, Step : 240, LR : 9.673755437409378e-06, Avg Loss : 0.1039\n",
            "Epoch: 0, Step : 250, LR : 9.649589173513776e-06, Avg Loss : 0.0999\n",
            "Epoch: 0, Step : 260, LR : 9.625422909618173e-06, Avg Loss : 0.1170\n",
            "Epoch: 0, Step : 270, LR : 9.601256645722573e-06, Avg Loss : 0.0930\n",
            "Epoch: 0, Step : 280, LR : 9.57709038182697e-06, Avg Loss : 0.0824\n",
            "Epoch: 0, Step : 290, LR : 9.552924117931368e-06, Avg Loss : 0.1146\n",
            "Epoch: 0, Step : 300, LR : 9.528757854035767e-06, Avg Loss : 0.0816\n",
            "Epoch: 0, Step : 310, LR : 9.504591590140166e-06, Avg Loss : 0.0786\n",
            "Epoch: 0, Step : 320, LR : 9.480425326244563e-06, Avg Loss : 0.0873\n",
            "Epoch: 0, Step : 330, LR : 9.456259062348961e-06, Avg Loss : 0.0837\n",
            "Epoch: 0, Step : 340, LR : 9.43209279845336e-06, Avg Loss : 0.0901\n",
            "Epoch: 0, Step : 350, LR : 9.40792653455776e-06, Avg Loss : 0.0949\n",
            "Epoch: 0, Step : 360, LR : 9.383760270662157e-06, Avg Loss : 0.1020\n",
            "Epoch: 0, Step : 370, LR : 9.359594006766554e-06, Avg Loss : 0.0978\n",
            "Epoch: 0, Step : 380, LR : 9.335427742870952e-06, Avg Loss : 0.0943\n",
            "Epoch: 0, Step : 390, LR : 9.311261478975351e-06, Avg Loss : 0.0919\n",
            "Epoch: 0, Step : 400, LR : 9.28709521507975e-06, Avg Loss : 0.0975\n",
            "Epoch: 0, Step : 410, LR : 9.262928951184148e-06, Avg Loss : 0.0813\n",
            "Epoch: 0, Step : 420, LR : 9.238762687288545e-06, Avg Loss : 0.0799\n",
            "Epoch: 0, Step : 430, LR : 9.214596423392945e-06, Avg Loss : 0.0915\n",
            "Epoch: 0, Step : 440, LR : 9.190430159497342e-06, Avg Loss : 0.0987\n",
            "Epoch: 0, Step : 450, LR : 9.16626389560174e-06, Avg Loss : 0.0783\n",
            "Epoch: 0, Step : 460, LR : 9.142097631706139e-06, Avg Loss : 0.0922\n",
            "Epoch: 0, Step : 470, LR : 9.117931367810538e-06, Avg Loss : 0.0999\n",
            "Epoch: 0, Step : 480, LR : 9.093765103914936e-06, Avg Loss : 0.0991\n",
            "Epoch: 0, Step : 490, LR : 9.069598840019333e-06, Avg Loss : 0.0771\n",
            "Epoch: 0, Step : 500, LR : 9.045432576123732e-06, Avg Loss : 0.0855\n",
            "Epoch: 0, Step : 510, LR : 9.021266312228131e-06, Avg Loss : 0.1091\n",
            "Epoch: 0, Step : 520, LR : 8.997100048332529e-06, Avg Loss : 0.0987\n",
            "Epoch: 0, Step : 530, LR : 8.972933784436927e-06, Avg Loss : 0.0760\n",
            "Epoch: 0, Step : 540, LR : 8.948767520541326e-06, Avg Loss : 0.1001\n",
            "Epoch: 0, Step : 550, LR : 8.924601256645723e-06, Avg Loss : 0.0682\n",
            "Epoch: 0, Step : 560, LR : 8.90043499275012e-06, Avg Loss : 0.1266\n",
            "Epoch: 0, Step : 570, LR : 8.87626872885452e-06, Avg Loss : 0.1053\n",
            "Epoch: 0, Step : 580, LR : 8.852102464958917e-06, Avg Loss : 0.1034\n",
            "Epoch: 0, Step : 590, LR : 8.827936201063317e-06, Avg Loss : 0.0913\n",
            "Epoch: 0, Step : 600, LR : 8.803769937167714e-06, Avg Loss : 0.0938\n",
            "Epoch: 0, Step : 610, LR : 8.779603673272112e-06, Avg Loss : 0.0891\n",
            "Epoch: 0, Step : 620, LR : 8.755437409376511e-06, Avg Loss : 0.0838\n",
            "Epoch: 0, Step : 630, LR : 8.73127114548091e-06, Avg Loss : 0.0768\n",
            "Epoch: 0, Step : 640, LR : 8.707104881585308e-06, Avg Loss : 0.0663\n",
            "Epoch: 0, Step : 650, LR : 8.682938617689705e-06, Avg Loss : 0.0804\n",
            "Epoch: 0, Step : 660, LR : 8.658772353794104e-06, Avg Loss : 0.0853\n",
            "Epoch: 0, Step : 670, LR : 8.634606089898504e-06, Avg Loss : 0.0961\n",
            "Epoch: 0, Step : 680, LR : 8.610439826002901e-06, Avg Loss : 0.0715\n",
            "Epoch: 0, Step : 690, LR : 8.586273562107299e-06, Avg Loss : 0.0751\n",
            "Epoch: 0, Step : 700, LR : 8.562107298211698e-06, Avg Loss : 0.0829\n",
            "Epoch: 0, Step : 710, LR : 8.537941034316095e-06, Avg Loss : 0.0744\n",
            "Epoch: 0, Step : 720, LR : 8.513774770420493e-06, Avg Loss : 0.0855\n",
            "Epoch: 0, Step : 730, LR : 8.489608506524892e-06, Avg Loss : 0.0921\n",
            "Epoch: 0, Step : 740, LR : 8.46544224262929e-06, Avg Loss : 0.0843\n",
            "Epoch: 0, Step : 750, LR : 8.441275978733689e-06, Avg Loss : 0.0804\n",
            "Epoch: 0, Step : 760, LR : 8.417109714838086e-06, Avg Loss : 0.0632\n",
            "Epoch: 0, Step : 770, LR : 8.392943450942484e-06, Avg Loss : 0.0918\n",
            "Epoch: 0, Step : 780, LR : 8.368777187046883e-06, Avg Loss : 0.0739\n",
            "Epoch: 0, Step : 790, LR : 8.344610923151282e-06, Avg Loss : 0.0741\n",
            "Epoch: 0, Step : 800, LR : 8.32044465925568e-06, Avg Loss : 0.0722\n",
            "Epoch: 0, Step : 810, LR : 8.296278395360077e-06, Avg Loss : 0.0822\n",
            "Epoch: 0, Step : 820, LR : 8.272112131464476e-06, Avg Loss : 0.0958\n",
            "Epoch: 0, Step : 830, LR : 8.247945867568876e-06, Avg Loss : 0.0854\n",
            "Epoch: 0, Step : 840, LR : 8.223779603673273e-06, Avg Loss : 0.0880\n",
            "Epoch: 0, Step : 850, LR : 8.19961333977767e-06, Avg Loss : 0.0868\n",
            "Epoch: 0, Step : 860, LR : 8.17544707588207e-06, Avg Loss : 0.0842\n",
            "Epoch: 0, Step : 870, LR : 8.151280811986467e-06, Avg Loss : 0.0752\n",
            "Epoch: 0, Step : 880, LR : 8.127114548090865e-06, Avg Loss : 0.0667\n",
            "Epoch: 0, Step : 890, LR : 8.102948284195264e-06, Avg Loss : 0.0632\n",
            "Epoch: 0, Step : 900, LR : 8.078782020299662e-06, Avg Loss : 0.0802\n",
            "Epoch: 0, Step : 910, LR : 8.054615756404061e-06, Avg Loss : 0.0912\n",
            "Epoch: 0, Step : 920, LR : 8.030449492508458e-06, Avg Loss : 0.0865\n",
            "Epoch: 0, Step : 930, LR : 8.006283228612856e-06, Avg Loss : 0.0919\n",
            "Epoch: 0, Step : 940, LR : 7.982116964717255e-06, Avg Loss : 0.0869\n",
            "Epoch: 0, Step : 950, LR : 7.957950700821654e-06, Avg Loss : 0.0744\n",
            "Epoch: 0, Step : 960, LR : 7.933784436926052e-06, Avg Loss : 0.0778\n",
            "Epoch: 0, Step : 970, LR : 7.90961817303045e-06, Avg Loss : 0.0868\n",
            "Epoch: 0, Step : 980, LR : 7.885451909134849e-06, Avg Loss : 0.0884\n",
            "Epoch: 0, Step : 990, LR : 7.861285645239248e-06, Avg Loss : 0.0878\n",
            "Epoch: 0, Step : 1000, LR : 7.837119381343645e-06, Avg Loss : 0.0810\n",
            "Epoch: 0, Step : 1010, LR : 7.812953117448043e-06, Avg Loss : 0.0692\n",
            "Epoch: 0, Step : 1020, LR : 7.788786853552442e-06, Avg Loss : 0.1036\n",
            "Epoch: 0, Step : 1030, LR : 7.76462058965684e-06, Avg Loss : 0.0924\n",
            "Epoch: 0, Step : 1040, LR : 7.740454325761237e-06, Avg Loss : 0.0767\n",
            "Epoch: 0, Step : 1050, LR : 7.716288061865636e-06, Avg Loss : 0.0730\n",
            "Epoch: 0, Step : 1060, LR : 7.692121797970035e-06, Avg Loss : 0.0655\n",
            "Epoch 0 Total Mean Loss : 0.1023\n",
            "*****Epoch 0 Train Finish*****\n",
            "\n",
            "*****Epoch 0 Valid Start*****\n",
            "Step: 0,  Pearson: tensor([0.7267])\n",
            "Step: 1,  Pearson: tensor([0.8397])\n",
            "Step: 2,  Pearson: tensor([0.9474])\n",
            "Step: 3,  Pearson: tensor([0.8428])\n",
            "Step: 4,  Pearson: tensor([0.9324])\n",
            "Step: 5,  Pearson: tensor([0.8959])\n",
            "Step: 6,  Pearson: tensor([0.8293])\n",
            "Step: 7,  Pearson: tensor([0.9151])\n",
            "Step: 8,  Pearson: tensor([0.8588])\n",
            "Step: 9,  Pearson: tensor([0.8264])\n",
            "Step: 10,  Pearson: tensor([0.9051])\n",
            "Step: 11,  Pearson: tensor([0.7526])\n",
            "Step: 12,  Pearson: tensor([0.8141])\n",
            "Step: 13,  Pearson: tensor([0.7206])\n",
            "Step: 14,  Pearson: tensor([0.7472])\n",
            "Step: 15,  Pearson: tensor([0.7083])\n",
            "Step: 16,  Pearson: tensor([0.6858])\n",
            "Step: 17,  Pearson: tensor([0.8560])\n",
            "Step: 18,  Pearson: tensor([0.8762])\n",
            "Step: 19,  Pearson: tensor([0.8014])\n",
            "Step: 20,  Pearson: tensor([0.8265])\n",
            "Step: 21,  Pearson: tensor([0.8744])\n",
            "Step: 22,  Pearson: tensor([0.8442])\n",
            "Step: 23,  Pearson: tensor([0.8135])\n",
            "Step: 24,  Pearson: tensor([0.8815])\n",
            "Step: 25,  Pearson: tensor([0.8588])\n",
            "Step: 26,  Pearson: tensor([0.9243])\n",
            "Step: 27,  Pearson: tensor([0.7725])\n",
            "Step: 28,  Pearson: tensor([0.8761])\n",
            "Step: 29,  Pearson: tensor([0.7966])\n",
            "Step: 30,  Pearson: tensor([0.8579])\n",
            "Step: 31,  Pearson: tensor([0.8959])\n",
            "Step: 32,  Pearson: tensor([0.8433])\n",
            "Step: 33,  Pearson: tensor([0.9422])\n",
            "Step: 34,  Pearson: tensor([0.8793])\n",
            "Step: 35,  Pearson: tensor([0.8368])\n",
            "Step: 36,  Pearson: tensor([0.9122])\n",
            "Step: 37,  Pearson: tensor([0.9385])\n",
            "Step: 38,  Pearson: tensor([0.8576])\n",
            "Step: 39,  Pearson: tensor([0.9593])\n",
            "Step: 40,  Pearson: tensor([0.8377])\n",
            "Step: 41,  Pearson: tensor([0.7033])\n",
            "Step: 42,  Pearson: tensor([0.8017])\n",
            "Step: 43,  Pearson: tensor([0.8885])\n",
            "Step: 44,  Pearson: tensor([0.7704])\n",
            "Step: 45,  Pearson: tensor([0.8677])\n",
            "Step: 46,  Pearson: tensor([0.8053])\n",
            "Step: 47,  Pearson: tensor([0.8530])\n",
            "Step: 48,  Pearson: tensor([0.8488])\n",
            "Step: 49,  Pearson: tensor([0.8570])\n",
            "Step: 50,  Pearson: tensor([0.6700])\n",
            "Step: 51,  Pearson: tensor([0.8243])\n",
            "Step: 52,  Pearson: tensor([0.9129])\n",
            "Step: 53,  Pearson: tensor([0.8282])\n",
            "Step: 54,  Pearson: tensor([0.8687])\n",
            "Step: 55,  Pearson: tensor([0.9484])\n",
            "Step: 56,  Pearson: tensor([0.8209])\n",
            "Step: 57,  Pearson: tensor([0.9150])\n",
            "Step: 58,  Pearson: tensor([0.7646])\n",
            "Step: 59,  Pearson: tensor([0.8468])\n",
            "Step: 60,  Pearson: tensor([0.8194])\n",
            "Step: 61,  Pearson: tensor([0.7964])\n",
            "Step: 62,  Pearson: tensor([0.8162])\n",
            "Step: 63,  Pearson: tensor([0.9029])\n",
            "Step: 64,  Pearson: tensor([0.8082])\n",
            "Step: 65,  Pearson: tensor([0.8759])\n",
            "Step: 66,  Pearson: tensor([0.8554])\n",
            "Step: 67,  Pearson: tensor([0.8018])\n",
            "Step: 68,  Pearson: tensor([0.7016])\n",
            "Step: 69,  Pearson: tensor([0.8708])\n",
            "Step: 70,  Pearson: tensor([0.8273])\n",
            "Step: 71,  Pearson: tensor([0.8399])\n",
            "Step: 72,  Pearson: tensor([0.7253])\n",
            "Step: 73,  Pearson: tensor([0.8096])\n",
            "Step: 74,  Pearson: tensor([0.8075])\n",
            "Step: 75,  Pearson: tensor([0.8744])\n",
            "Step: 76,  Pearson: tensor([0.8775])\n",
            "Step: 77,  Pearson: tensor([0.7775])\n",
            "Step: 78,  Pearson: tensor([0.8144])\n",
            "Step: 79,  Pearson: tensor([0.8858])\n",
            "Step: 80,  Pearson: tensor([0.7281])\n",
            "Step: 81,  Pearson: tensor([0.7522])\n",
            "Step: 82,  Pearson: tensor([0.8126])\n",
            "Step: 83,  Pearson: tensor([0.9215])\n",
            "Step: 84,  Pearson: tensor([0.9180])\n",
            "Step: 85,  Pearson: tensor([0.8783])\n",
            "Step: 86,  Pearson: tensor([0.8249])\n",
            "Step: 87,  Pearson: tensor([0.8531])\n",
            "Step: 88,  Pearson: tensor([0.8287])\n",
            "Step: 89,  Pearson: tensor([0.8777])\n",
            "Step: 90,  Pearson: tensor([0.8867])\n",
            "Step: 91,  Pearson: tensor([0.9142])\n",
            "Step: 92,  Pearson: tensor([0.7962])\n",
            "Step: 93,  Pearson: tensor([0.8410])\n",
            "Step: 94,  Pearson: tensor([0.8832])\n",
            "Step: 95,  Pearson: tensor([0.8419])\n",
            "Step: 96,  Pearson: tensor([0.8843])\n",
            "Step: 97,  Pearson: tensor([0.7742])\n",
            "Step: 98,  Pearson: tensor([0.8513])\n",
            "Step: 99,  Pearson: tensor([0.7686])\n",
            "Step: 100,  Pearson: tensor([0.9044])\n",
            "Step: 101,  Pearson: tensor([0.8389])\n",
            "Step: 102,  Pearson: tensor([0.9398])\n",
            "Step: 103,  Pearson: tensor([0.8070])\n",
            "Step: 104,  Pearson: tensor([0.8160])\n",
            "Step: 105,  Pearson: tensor([0.8921])\n",
            "Step: 106,  Pearson: tensor([0.8464])\n",
            "Step: 107,  Pearson: tensor([0.8082])\n",
            "Step: 108,  Pearson: tensor([0.9033])\n",
            "Step: 109,  Pearson: tensor([0.8757])\n",
            "Step: 110,  Pearson: tensor([0.9083])\n",
            "Step: 111,  Pearson: tensor([0.8687])\n",
            "Step: 112,  Pearson: tensor([0.8728])\n",
            "Step: 113,  Pearson: tensor([0.7239])\n",
            "Step: 114,  Pearson: tensor([0.8659])\n",
            "Step: 115,  Pearson: tensor([0.8252])\n",
            "Step: 116,  Pearson: tensor([0.7677])\n",
            "Step: 117,  Pearson: tensor([0.7646])\n",
            "Step: 118,  Pearson: tensor([0.9549])\n",
            "Step: 119,  Pearson: tensor([0.8335])\n",
            "Step: 120,  Pearson: tensor([0.8705])\n",
            "Step: 121,  Pearson: tensor([0.7871])\n",
            "Step: 122,  Pearson: tensor([0.9330])\n",
            "Step: 123,  Pearson: tensor([0.7456])\n",
            "Step: 124,  Pearson: tensor([0.9318])\n",
            "Step: 125,  Pearson: tensor([0.8669])\n",
            "Step: 126,  Pearson: tensor([0.8675])\n",
            "Step: 127,  Pearson: tensor([0.8652])\n",
            "Step: 128,  Pearson: tensor([0.9321])\n",
            "Step: 129,  Pearson: tensor([0.8413])\n",
            "Step: 130,  Pearson: tensor([0.7791])\n",
            "Step: 131,  Pearson: tensor([0.8172])\n",
            "Step: 132,  Pearson: tensor([0.8310])\n",
            "Step: 133,  Pearson: tensor([0.8165])\n",
            "Step: 134,  Pearson: tensor([0.7485])\n",
            "Step: 135,  Pearson: tensor([0.8305])\n",
            "Step: 136,  Pearson: tensor([0.7568])\n",
            "Step: 137,  Pearson: tensor([0.9368])\n",
            "Step: 138,  Pearson: tensor([0.7172])\n",
            "Step: 139,  Pearson: tensor([0.9210])\n",
            "Step: 140,  Pearson: tensor([0.8902])\n",
            "Step: 141,  Pearson: tensor([0.8096])\n",
            "Step: 142,  Pearson: tensor([0.8767])\n",
            "Step: 143,  Pearson: tensor([0.8422])\n",
            "Step: 144,  Pearson: tensor([0.8844])\n",
            "Step: 145,  Pearson: tensor([0.8926])\n",
            "Step: 146,  Pearson: tensor([0.8374])\n",
            "Step: 147,  Pearson: tensor([0.8891])\n",
            "Step: 148,  Pearson: tensor([0.8599])\n",
            "Step: 149,  Pearson: tensor([0.8984])\n",
            "Step: 150,  Pearson: tensor([0.8746])\n",
            "Step: 151,  Pearson: tensor([0.9155])\n",
            "Step: 152,  Pearson: tensor([0.8661])\n",
            "Step: 153,  Pearson: tensor([0.7298])\n",
            "Step: 154,  Pearson: tensor([0.8830])\n",
            "Step: 155,  Pearson: tensor([0.8791])\n",
            "Step: 156,  Pearson: tensor([0.8696])\n",
            "Step: 157,  Pearson: tensor([0.9238])\n",
            "Step: 158,  Pearson: tensor([0.8360])\n",
            "Step: 159,  Pearson: tensor([0.8924])\n",
            "Step: 160,  Pearson: tensor([0.8695])\n",
            "Step: 161,  Pearson: tensor([0.9026])\n",
            "Step: 162,  Pearson: tensor([0.7443])\n",
            "Step: 163,  Pearson: tensor([0.8318])\n",
            "Step: 164,  Pearson: tensor([0.8895])\n",
            "Step: 165,  Pearson: tensor([0.9312])\n",
            "Step: 166,  Pearson: tensor([0.8954])\n",
            "Step: 167,  Pearson: tensor([0.7763])\n",
            "Step: 168,  Pearson: tensor([0.8001])\n",
            "Step: 169,  Pearson: tensor([0.8612])\n",
            "Step: 170,  Pearson: tensor([0.8253])\n",
            "Step: 171,  Pearson: tensor([0.9112])\n",
            "Step: 172,  Pearson: tensor([0.9418])\n",
            "Step: 173,  Pearson: tensor([0.8342])\n",
            "Step: 174,  Pearson: tensor([0.9150])\n",
            "Step: 175,  Pearson: tensor([0.7143])\n",
            "Step: 176,  Pearson: tensor([0.9210])\n",
            "Step: 177,  Pearson: tensor([0.9057])\n",
            "Step: 178,  Pearson: tensor([0.8293])\n",
            "Step: 179,  Pearson: tensor([0.7505])\n",
            "Step: 180,  Pearson: tensor([0.7606])\n",
            "Step: 181,  Pearson: tensor([0.8016])\n",
            "Step: 182,  Pearson: tensor([0.6684])\n",
            "Step: 183,  Pearson: tensor([0.8983])\n",
            "Step: 184,  Pearson: tensor([0.8181])\n",
            "Step: 185,  Pearson: tensor([0.9096])\n",
            "Step: 186,  Pearson: tensor([0.7710])\n",
            "Step: 187,  Pearson: tensor([0.8161])\n",
            "Step: 188,  Pearson: tensor([0.8106])\n",
            "Step: 189,  Pearson: tensor([0.7983])\n",
            "Step: 190,  Pearson: tensor([0.8227])\n",
            "Step: 191,  Pearson: tensor([0.8523])\n",
            "Step: 192,  Pearson: tensor([0.8252])\n",
            "Step: 193,  Pearson: tensor([0.8292])\n",
            "Step: 194,  Pearson: tensor([0.8640])\n",
            "Step: 195,  Pearson: tensor([0.9112])\n",
            "Step: 196,  Pearson: tensor([0.8468])\n",
            "Step: 197,  Pearson: tensor([0.8279])\n",
            "Step: 198,  Pearson: tensor([0.8184])\n",
            "Step: 199,  Pearson: tensor([0.9151])\n",
            "Step: 200,  Pearson: tensor([0.8332])\n",
            "Step: 201,  Pearson: tensor([0.8786])\n",
            "Step: 202,  Pearson: tensor([0.8632])\n",
            "Step: 203,  Pearson: tensor([0.9090])\n",
            "Step: 204,  Pearson: tensor([0.9639])\n",
            "Step: 205,  Pearson: tensor([0.9059])\n",
            "Step: 206,  Pearson: tensor([0.8785])\n",
            "Step: 207,  Pearson: tensor([0.7654])\n",
            "Step: 208,  Pearson: tensor([0.7784])\n",
            "Step: 209,  Pearson: tensor([0.8722])\n",
            "Step: 210,  Pearson: tensor([0.8587])\n",
            "Step: 211,  Pearson: tensor([0.8520])\n",
            "Step: 212,  Pearson: tensor([0.8351])\n",
            "Step: 213,  Pearson: tensor([0.7913])\n",
            "Step: 214,  Pearson: tensor([0.7403])\n",
            "Step: 215,  Pearson: tensor([0.8208])\n",
            "Step: 216,  Pearson: tensor([0.7892])\n",
            "Step: 217,  Pearson: tensor([0.8004])\n",
            "Step: 218,  Pearson: tensor([0.8006])\n",
            "Step: 219,  Pearson: tensor([0.9123])\n",
            "Step: 220,  Pearson: tensor([0.7661])\n",
            "Step: 221,  Pearson: tensor([0.9749])\n",
            "Step: 222,  Pearson: tensor([0.8381])\n",
            "Step: 223,  Pearson: tensor([0.9417])\n",
            "Step: 224,  Pearson: tensor([0.8982])\n",
            "Step: 225,  Pearson: tensor([0.9158])\n",
            "Step: 226,  Pearson: tensor([0.7709])\n",
            "Step: 227,  Pearson: tensor([0.8096])\n",
            "Epoch 0 Valid Loss : 0.0731540847602382 Valid Pearsonr : tensor([0.8441]) ValidF1 : 0.14472177696359056\n",
            "*****Epoch 0 Valid Finish*****\n",
            "\n",
            "SAVING EPOCH 0 ...\n",
            "****** STARTING TO TRAIN EPOCH #1 ******\n",
            "Epoch: 1, Step : 10, LR : 7.665538907684872e-06, Avg Loss : 0.0461\n",
            "Epoch: 1, Step : 20, LR : 7.641372643789271e-06, Avg Loss : 0.0508\n",
            "Epoch: 1, Step : 30, LR : 7.617206379893669e-06, Avg Loss : 0.0506\n",
            "Epoch: 1, Step : 40, LR : 7.593040115998067e-06, Avg Loss : 0.0634\n",
            "Epoch: 1, Step : 50, LR : 7.568873852102465e-06, Avg Loss : 0.0581\n",
            "Epoch: 1, Step : 60, LR : 7.544707588206864e-06, Avg Loss : 0.0593\n",
            "Epoch: 1, Step : 70, LR : 7.520541324311262e-06, Avg Loss : 0.0508\n",
            "Epoch: 1, Step : 80, LR : 7.496375060415661e-06, Avg Loss : 0.0507\n",
            "Epoch: 1, Step : 90, LR : 7.472208796520058e-06, Avg Loss : 0.0455\n",
            "Epoch: 1, Step : 100, LR : 7.448042532624457e-06, Avg Loss : 0.0518\n",
            "Epoch: 1, Step : 110, LR : 7.423876268728855e-06, Avg Loss : 0.0572\n",
            "Epoch: 1, Step : 120, LR : 7.399710004833253e-06, Avg Loss : 0.0658\n",
            "Epoch: 1, Step : 130, LR : 7.375543740937652e-06, Avg Loss : 0.0557\n",
            "Epoch: 1, Step : 140, LR : 7.35137747704205e-06, Avg Loss : 0.0565\n",
            "Epoch: 1, Step : 150, LR : 7.327211213146448e-06, Avg Loss : 0.0656\n",
            "Epoch: 1, Step : 160, LR : 7.303044949250846e-06, Avg Loss : 0.0460\n",
            "Epoch: 1, Step : 170, LR : 7.278878685355245e-06, Avg Loss : 0.0684\n",
            "Epoch: 1, Step : 180, LR : 7.2547124214596435e-06, Avg Loss : 0.0484\n",
            "Epoch: 1, Step : 190, LR : 7.230546157564041e-06, Avg Loss : 0.0523\n",
            "Epoch: 1, Step : 200, LR : 7.206379893668439e-06, Avg Loss : 0.0470\n",
            "Epoch: 1, Step : 210, LR : 7.182213629772837e-06, Avg Loss : 0.0593\n",
            "Epoch: 1, Step : 220, LR : 7.158047365877236e-06, Avg Loss : 0.0550\n",
            "Epoch: 1, Step : 230, LR : 7.1338811019816345e-06, Avg Loss : 0.0466\n",
            "Epoch: 1, Step : 240, LR : 7.109714838086033e-06, Avg Loss : 0.0411\n",
            "Epoch: 1, Step : 250, LR : 7.08554857419043e-06, Avg Loss : 0.0592\n",
            "Epoch: 1, Step : 260, LR : 7.061382310294829e-06, Avg Loss : 0.0463\n",
            "Epoch: 1, Step : 270, LR : 7.037216046399227e-06, Avg Loss : 0.0475\n",
            "Epoch: 1, Step : 280, LR : 7.013049782503626e-06, Avg Loss : 0.0572\n",
            "Epoch: 1, Step : 290, LR : 6.988883518608024e-06, Avg Loss : 0.0492\n",
            "Epoch: 1, Step : 300, LR : 6.964717254712422e-06, Avg Loss : 0.0690\n",
            "Epoch: 1, Step : 310, LR : 6.94055099081682e-06, Avg Loss : 0.0504\n",
            "Epoch: 1, Step : 320, LR : 6.916384726921218e-06, Avg Loss : 0.0514\n",
            "Epoch: 1, Step : 330, LR : 6.892218463025617e-06, Avg Loss : 0.0445\n",
            "Epoch: 1, Step : 340, LR : 6.868052199130016e-06, Avg Loss : 0.0515\n",
            "Epoch: 1, Step : 350, LR : 6.843885935234413e-06, Avg Loss : 0.0409\n",
            "Epoch: 1, Step : 360, LR : 6.8197196713388115e-06, Avg Loss : 0.0451\n",
            "Epoch: 1, Step : 370, LR : 6.79555340744321e-06, Avg Loss : 0.0689\n",
            "Epoch: 1, Step : 380, LR : 6.771387143547608e-06, Avg Loss : 0.0477\n",
            "Epoch: 1, Step : 390, LR : 6.7472208796520066e-06, Avg Loss : 0.0526\n",
            "Epoch: 1, Step : 400, LR : 6.723054615756405e-06, Avg Loss : 0.0528\n",
            "Epoch: 1, Step : 410, LR : 6.6988883518608024e-06, Avg Loss : 0.0589\n",
            "Epoch: 1, Step : 420, LR : 6.674722087965201e-06, Avg Loss : 0.0544\n",
            "Epoch: 1, Step : 430, LR : 6.650555824069599e-06, Avg Loss : 0.0547\n",
            "Epoch: 1, Step : 440, LR : 6.626389560173998e-06, Avg Loss : 0.0701\n",
            "Epoch: 1, Step : 450, LR : 6.602223296278396e-06, Avg Loss : 0.0369\n",
            "Epoch: 1, Step : 460, LR : 6.578057032382794e-06, Avg Loss : 0.0594\n",
            "Epoch: 1, Step : 470, LR : 6.553890768487192e-06, Avg Loss : 0.0585\n",
            "Epoch: 1, Step : 480, LR : 6.52972450459159e-06, Avg Loss : 0.0551\n",
            "Epoch: 1, Step : 490, LR : 6.505558240695989e-06, Avg Loss : 0.0488\n",
            "Epoch: 1, Step : 500, LR : 6.481391976800388e-06, Avg Loss : 0.0643\n",
            "Epoch: 1, Step : 510, LR : 6.457225712904785e-06, Avg Loss : 0.0476\n",
            "Epoch: 1, Step : 520, LR : 6.433059449009184e-06, Avg Loss : 0.0395\n",
            "Epoch: 1, Step : 530, LR : 6.408893185113582e-06, Avg Loss : 0.0416\n",
            "Epoch: 1, Step : 540, LR : 6.384726921217981e-06, Avg Loss : 0.0451\n",
            "Epoch: 1, Step : 550, LR : 6.360560657322379e-06, Avg Loss : 0.0668\n",
            "Epoch: 1, Step : 560, LR : 6.336394393426777e-06, Avg Loss : 0.0450\n",
            "Epoch: 1, Step : 570, LR : 6.3122281295311745e-06, Avg Loss : 0.0549\n",
            "Epoch: 1, Step : 580, LR : 6.288061865635573e-06, Avg Loss : 0.0471\n",
            "Epoch: 1, Step : 590, LR : 6.263895601739971e-06, Avg Loss : 0.0472\n",
            "Epoch: 1, Step : 600, LR : 6.2397293378443705e-06, Avg Loss : 0.0443\n",
            "Epoch: 1, Step : 610, LR : 6.215563073948768e-06, Avg Loss : 0.0544\n",
            "Epoch: 1, Step : 620, LR : 6.191396810053166e-06, Avg Loss : 0.0546\n",
            "Epoch: 1, Step : 630, LR : 6.167230546157565e-06, Avg Loss : 0.0601\n",
            "Epoch: 1, Step : 640, LR : 6.143064282261962e-06, Avg Loss : 0.0517\n",
            "Epoch: 1, Step : 650, LR : 6.1188980183663614e-06, Avg Loss : 0.0458\n",
            "Epoch: 1, Step : 660, LR : 6.09473175447076e-06, Avg Loss : 0.0469\n",
            "Epoch: 1, Step : 670, LR : 6.070565490575157e-06, Avg Loss : 0.0576\n",
            "Epoch: 1, Step : 680, LR : 6.046399226679556e-06, Avg Loss : 0.0570\n",
            "Epoch: 1, Step : 690, LR : 6.022232962783954e-06, Avg Loss : 0.0524\n",
            "Epoch: 1, Step : 700, LR : 5.9980666988883515e-06, Avg Loss : 0.0713\n",
            "Epoch: 1, Step : 710, LR : 5.973900434992751e-06, Avg Loss : 0.0570\n",
            "Epoch: 1, Step : 720, LR : 5.949734171097149e-06, Avg Loss : 0.0565\n",
            "Epoch: 1, Step : 730, LR : 5.9255679072015475e-06, Avg Loss : 0.0525\n",
            "Epoch: 1, Step : 740, LR : 5.901401643305945e-06, Avg Loss : 0.0538\n",
            "Epoch: 1, Step : 750, LR : 5.877235379410343e-06, Avg Loss : 0.0372\n",
            "Epoch: 1, Step : 760, LR : 5.8530691155147426e-06, Avg Loss : 0.0474\n",
            "Epoch: 1, Step : 770, LR : 5.82890285161914e-06, Avg Loss : 0.0479\n",
            "Epoch: 1, Step : 780, LR : 5.8047365877235384e-06, Avg Loss : 0.0473\n",
            "Epoch: 1, Step : 790, LR : 5.780570323827937e-06, Avg Loss : 0.0417\n",
            "Epoch: 1, Step : 800, LR : 5.756404059932334e-06, Avg Loss : 0.0673\n",
            "Epoch: 1, Step : 810, LR : 5.7322377960367335e-06, Avg Loss : 0.0550\n",
            "Epoch: 1, Step : 820, LR : 5.708071532141132e-06, Avg Loss : 0.0470\n",
            "Epoch: 1, Step : 830, LR : 5.683905268245529e-06, Avg Loss : 0.0506\n",
            "Epoch: 1, Step : 840, LR : 5.659739004349928e-06, Avg Loss : 0.0488\n",
            "Epoch: 1, Step : 850, LR : 5.635572740454326e-06, Avg Loss : 0.0459\n",
            "Epoch: 1, Step : 860, LR : 5.611406476558724e-06, Avg Loss : 0.0466\n",
            "Epoch: 1, Step : 870, LR : 5.587240212663123e-06, Avg Loss : 0.0527\n",
            "Epoch: 1, Step : 880, LR : 5.563073948767521e-06, Avg Loss : 0.0528\n",
            "Epoch: 1, Step : 890, LR : 5.5389076848719196e-06, Avg Loss : 0.0616\n",
            "Epoch: 1, Step : 900, LR : 5.514741420976317e-06, Avg Loss : 0.0361\n",
            "Epoch: 1, Step : 910, LR : 5.4905751570807154e-06, Avg Loss : 0.0547\n",
            "Epoch: 1, Step : 920, LR : 5.466408893185115e-06, Avg Loss : 0.0453\n",
            "Epoch: 1, Step : 930, LR : 5.442242629289512e-06, Avg Loss : 0.0406\n",
            "Epoch: 1, Step : 940, LR : 5.4180763653939105e-06, Avg Loss : 0.0392\n",
            "Epoch: 1, Step : 950, LR : 5.393910101498309e-06, Avg Loss : 0.0444\n",
            "Epoch: 1, Step : 960, LR : 5.369743837602706e-06, Avg Loss : 0.0451\n",
            "Epoch: 1, Step : 970, LR : 5.345577573707106e-06, Avg Loss : 0.0517\n",
            "Epoch: 1, Step : 980, LR : 5.321411309811504e-06, Avg Loss : 0.0511\n",
            "Epoch: 1, Step : 990, LR : 5.297245045915902e-06, Avg Loss : 0.0333\n",
            "Epoch: 1, Step : 1000, LR : 5.2730787820203e-06, Avg Loss : 0.0419\n",
            "Epoch: 1, Step : 1010, LR : 5.248912518124698e-06, Avg Loss : 0.0561\n",
            "Epoch: 1, Step : 1020, LR : 5.224746254229096e-06, Avg Loss : 0.0474\n",
            "Epoch: 1, Step : 1030, LR : 5.200579990333495e-06, Avg Loss : 0.0447\n",
            "Epoch: 1, Step : 1040, LR : 5.176413726437893e-06, Avg Loss : 0.0617\n",
            "Epoch: 1, Step : 1050, LR : 5.152247462542292e-06, Avg Loss : 0.0452\n",
            "Epoch: 1, Step : 1060, LR : 5.128081198646689e-06, Avg Loss : 0.0491\n",
            "Epoch 1 Total Mean Loss : 0.0516\n",
            "*****Epoch 1 Train Finish*****\n",
            "\n",
            "*****Epoch 1 Valid Start*****\n",
            "Step: 0,  Pearson: tensor([0.7543])\n",
            "Step: 1,  Pearson: tensor([0.8117])\n",
            "Step: 2,  Pearson: tensor([0.9336])\n",
            "Step: 3,  Pearson: tensor([0.8901])\n",
            "Step: 4,  Pearson: tensor([0.9565])\n",
            "Step: 5,  Pearson: tensor([0.8904])\n",
            "Step: 6,  Pearson: tensor([0.7619])\n",
            "Step: 7,  Pearson: tensor([0.9146])\n",
            "Step: 8,  Pearson: tensor([0.8572])\n",
            "Step: 9,  Pearson: tensor([0.8015])\n",
            "Step: 10,  Pearson: tensor([0.9073])\n",
            "Step: 11,  Pearson: tensor([0.7565])\n",
            "Step: 12,  Pearson: tensor([0.8022])\n",
            "Step: 13,  Pearson: tensor([0.6659])\n",
            "Step: 14,  Pearson: tensor([0.7145])\n",
            "Step: 15,  Pearson: tensor([0.6835])\n",
            "Step: 16,  Pearson: tensor([0.6535])\n",
            "Step: 17,  Pearson: tensor([0.8716])\n",
            "Step: 18,  Pearson: tensor([0.8670])\n",
            "Step: 19,  Pearson: tensor([0.7555])\n",
            "Step: 20,  Pearson: tensor([0.8080])\n",
            "Step: 21,  Pearson: tensor([0.8634])\n",
            "Step: 22,  Pearson: tensor([0.8360])\n",
            "Step: 23,  Pearson: tensor([0.7976])\n",
            "Step: 24,  Pearson: tensor([0.8688])\n",
            "Step: 25,  Pearson: tensor([0.8543])\n",
            "Step: 26,  Pearson: tensor([0.9182])\n",
            "Step: 27,  Pearson: tensor([0.7385])\n",
            "Step: 28,  Pearson: tensor([0.8808])\n",
            "Step: 29,  Pearson: tensor([0.6938])\n",
            "Step: 30,  Pearson: tensor([0.8616])\n",
            "Step: 31,  Pearson: tensor([0.9003])\n",
            "Step: 32,  Pearson: tensor([0.8380])\n",
            "Step: 33,  Pearson: tensor([0.9564])\n",
            "Step: 34,  Pearson: tensor([0.9035])\n",
            "Step: 35,  Pearson: tensor([0.8155])\n",
            "Step: 36,  Pearson: tensor([0.9212])\n",
            "Step: 37,  Pearson: tensor([0.9329])\n",
            "Step: 38,  Pearson: tensor([0.8699])\n",
            "Step: 39,  Pearson: tensor([0.9659])\n",
            "Step: 40,  Pearson: tensor([0.8030])\n",
            "Step: 41,  Pearson: tensor([0.6910])\n",
            "Step: 42,  Pearson: tensor([0.7994])\n",
            "Step: 43,  Pearson: tensor([0.8519])\n",
            "Step: 44,  Pearson: tensor([0.7780])\n",
            "Step: 45,  Pearson: tensor([0.9013])\n",
            "Step: 46,  Pearson: tensor([0.8090])\n",
            "Step: 47,  Pearson: tensor([0.8337])\n",
            "Step: 48,  Pearson: tensor([0.8411])\n",
            "Step: 49,  Pearson: tensor([0.8165])\n",
            "Step: 50,  Pearson: tensor([0.6939])\n",
            "Step: 51,  Pearson: tensor([0.8108])\n",
            "Step: 52,  Pearson: tensor([0.9195])\n",
            "Step: 53,  Pearson: tensor([0.8031])\n",
            "Step: 54,  Pearson: tensor([0.8992])\n",
            "Step: 55,  Pearson: tensor([0.9521])\n",
            "Step: 56,  Pearson: tensor([0.7920])\n",
            "Step: 57,  Pearson: tensor([0.8887])\n",
            "Step: 58,  Pearson: tensor([0.7721])\n",
            "Step: 59,  Pearson: tensor([0.8600])\n",
            "Step: 60,  Pearson: tensor([0.8610])\n",
            "Step: 61,  Pearson: tensor([0.8201])\n",
            "Step: 62,  Pearson: tensor([0.8512])\n",
            "Step: 63,  Pearson: tensor([0.9233])\n",
            "Step: 64,  Pearson: tensor([0.8074])\n",
            "Step: 65,  Pearson: tensor([0.8214])\n",
            "Step: 66,  Pearson: tensor([0.8787])\n",
            "Step: 67,  Pearson: tensor([0.8202])\n",
            "Step: 68,  Pearson: tensor([0.6604])\n",
            "Step: 69,  Pearson: tensor([0.8775])\n",
            "Step: 70,  Pearson: tensor([0.8213])\n",
            "Step: 71,  Pearson: tensor([0.8196])\n",
            "Step: 72,  Pearson: tensor([0.7197])\n",
            "Step: 73,  Pearson: tensor([0.8368])\n",
            "Step: 74,  Pearson: tensor([0.7547])\n",
            "Step: 75,  Pearson: tensor([0.8722])\n",
            "Step: 76,  Pearson: tensor([0.8831])\n",
            "Step: 77,  Pearson: tensor([0.7848])\n",
            "Step: 78,  Pearson: tensor([0.7782])\n",
            "Step: 79,  Pearson: tensor([0.8651])\n",
            "Step: 80,  Pearson: tensor([0.7586])\n",
            "Step: 81,  Pearson: tensor([0.7508])\n",
            "Step: 82,  Pearson: tensor([0.7761])\n",
            "Step: 83,  Pearson: tensor([0.9033])\n",
            "Step: 84,  Pearson: tensor([0.9005])\n",
            "Step: 85,  Pearson: tensor([0.8701])\n",
            "Step: 86,  Pearson: tensor([0.8380])\n",
            "Step: 87,  Pearson: tensor([0.8300])\n",
            "Step: 88,  Pearson: tensor([0.8406])\n",
            "Step: 89,  Pearson: tensor([0.8620])\n",
            "Step: 90,  Pearson: tensor([0.8961])\n",
            "Step: 91,  Pearson: tensor([0.9022])\n",
            "Step: 92,  Pearson: tensor([0.7895])\n",
            "Step: 93,  Pearson: tensor([0.8588])\n",
            "Step: 94,  Pearson: tensor([0.8696])\n",
            "Step: 95,  Pearson: tensor([0.8262])\n",
            "Step: 96,  Pearson: tensor([0.8678])\n",
            "Step: 97,  Pearson: tensor([0.7995])\n",
            "Step: 98,  Pearson: tensor([0.8553])\n",
            "Step: 99,  Pearson: tensor([0.8015])\n",
            "Step: 100,  Pearson: tensor([0.9030])\n",
            "Step: 101,  Pearson: tensor([0.8213])\n",
            "Step: 102,  Pearson: tensor([0.9422])\n",
            "Step: 103,  Pearson: tensor([0.8597])\n",
            "Step: 104,  Pearson: tensor([0.8254])\n",
            "Step: 105,  Pearson: tensor([0.8867])\n",
            "Step: 106,  Pearson: tensor([0.8546])\n",
            "Step: 107,  Pearson: tensor([0.8665])\n",
            "Step: 108,  Pearson: tensor([0.8949])\n",
            "Step: 109,  Pearson: tensor([0.8579])\n",
            "Step: 110,  Pearson: tensor([0.9012])\n",
            "Step: 111,  Pearson: tensor([0.8616])\n",
            "Step: 112,  Pearson: tensor([0.8774])\n",
            "Step: 113,  Pearson: tensor([0.7534])\n",
            "Step: 114,  Pearson: tensor([0.8568])\n",
            "Step: 115,  Pearson: tensor([0.8194])\n",
            "Step: 116,  Pearson: tensor([0.7453])\n",
            "Step: 117,  Pearson: tensor([0.7648])\n",
            "Step: 118,  Pearson: tensor([0.9249])\n",
            "Step: 119,  Pearson: tensor([0.8502])\n",
            "Step: 120,  Pearson: tensor([0.8606])\n",
            "Step: 121,  Pearson: tensor([0.7813])\n",
            "Step: 122,  Pearson: tensor([0.9318])\n",
            "Step: 123,  Pearson: tensor([0.7293])\n",
            "Step: 124,  Pearson: tensor([0.9486])\n",
            "Step: 125,  Pearson: tensor([0.8379])\n",
            "Step: 126,  Pearson: tensor([0.8501])\n",
            "Step: 127,  Pearson: tensor([0.8809])\n",
            "Step: 128,  Pearson: tensor([0.9486])\n",
            "Step: 129,  Pearson: tensor([0.8734])\n",
            "Step: 130,  Pearson: tensor([0.7596])\n",
            "Step: 131,  Pearson: tensor([0.8443])\n",
            "Step: 132,  Pearson: tensor([0.8517])\n",
            "Step: 133,  Pearson: tensor([0.8323])\n",
            "Step: 134,  Pearson: tensor([0.7522])\n",
            "Step: 135,  Pearson: tensor([0.8256])\n",
            "Step: 136,  Pearson: tensor([0.7106])\n",
            "Step: 137,  Pearson: tensor([0.9355])\n",
            "Step: 138,  Pearson: tensor([0.6989])\n",
            "Step: 139,  Pearson: tensor([0.9274])\n",
            "Step: 140,  Pearson: tensor([0.8933])\n",
            "Step: 141,  Pearson: tensor([0.8139])\n",
            "Step: 142,  Pearson: tensor([0.8643])\n",
            "Step: 143,  Pearson: tensor([0.8165])\n",
            "Step: 144,  Pearson: tensor([0.8860])\n",
            "Step: 145,  Pearson: tensor([0.9040])\n",
            "Step: 146,  Pearson: tensor([0.8296])\n",
            "Step: 147,  Pearson: tensor([0.8706])\n",
            "Step: 148,  Pearson: tensor([0.8508])\n",
            "Step: 149,  Pearson: tensor([0.8878])\n",
            "Step: 150,  Pearson: tensor([0.8881])\n",
            "Step: 151,  Pearson: tensor([0.9268])\n",
            "Step: 152,  Pearson: tensor([0.8898])\n",
            "Step: 153,  Pearson: tensor([0.7317])\n",
            "Step: 154,  Pearson: tensor([0.8525])\n",
            "Step: 155,  Pearson: tensor([0.8612])\n",
            "Step: 156,  Pearson: tensor([0.8944])\n",
            "Step: 157,  Pearson: tensor([0.9283])\n",
            "Step: 158,  Pearson: tensor([0.8494])\n",
            "Step: 159,  Pearson: tensor([0.8733])\n",
            "Step: 160,  Pearson: tensor([0.8789])\n",
            "Step: 161,  Pearson: tensor([0.9138])\n",
            "Step: 162,  Pearson: tensor([0.7787])\n",
            "Step: 163,  Pearson: tensor([0.8117])\n",
            "Step: 164,  Pearson: tensor([0.9247])\n",
            "Step: 165,  Pearson: tensor([0.9239])\n",
            "Step: 166,  Pearson: tensor([0.8830])\n",
            "Step: 167,  Pearson: tensor([0.7697])\n",
            "Step: 168,  Pearson: tensor([0.7897])\n",
            "Step: 169,  Pearson: tensor([0.8576])\n",
            "Step: 170,  Pearson: tensor([0.8797])\n",
            "Step: 171,  Pearson: tensor([0.8918])\n",
            "Step: 172,  Pearson: tensor([0.9553])\n",
            "Step: 173,  Pearson: tensor([0.8128])\n",
            "Step: 174,  Pearson: tensor([0.9245])\n",
            "Step: 175,  Pearson: tensor([0.6943])\n",
            "Step: 176,  Pearson: tensor([0.8863])\n",
            "Step: 177,  Pearson: tensor([0.9031])\n",
            "Step: 178,  Pearson: tensor([0.8320])\n",
            "Step: 179,  Pearson: tensor([0.7358])\n",
            "Step: 180,  Pearson: tensor([0.7703])\n",
            "Step: 181,  Pearson: tensor([0.8369])\n",
            "Step: 182,  Pearson: tensor([0.6584])\n",
            "Step: 183,  Pearson: tensor([0.8938])\n",
            "Step: 184,  Pearson: tensor([0.7682])\n",
            "Step: 185,  Pearson: tensor([0.8944])\n",
            "Step: 186,  Pearson: tensor([0.8177])\n",
            "Step: 187,  Pearson: tensor([0.8447])\n",
            "Step: 188,  Pearson: tensor([0.8106])\n",
            "Step: 189,  Pearson: tensor([0.7850])\n",
            "Step: 190,  Pearson: tensor([0.8559])\n",
            "Step: 191,  Pearson: tensor([0.8015])\n",
            "Step: 192,  Pearson: tensor([0.7816])\n",
            "Step: 193,  Pearson: tensor([0.8132])\n",
            "Step: 194,  Pearson: tensor([0.8824])\n",
            "Step: 195,  Pearson: tensor([0.8430])\n",
            "Step: 196,  Pearson: tensor([0.8605])\n",
            "Step: 197,  Pearson: tensor([0.8760])\n",
            "Step: 198,  Pearson: tensor([0.7965])\n",
            "Step: 199,  Pearson: tensor([0.9439])\n",
            "Step: 200,  Pearson: tensor([0.8563])\n",
            "Step: 201,  Pearson: tensor([0.8787])\n",
            "Step: 202,  Pearson: tensor([0.8457])\n",
            "Step: 203,  Pearson: tensor([0.9092])\n",
            "Step: 204,  Pearson: tensor([0.9687])\n",
            "Step: 205,  Pearson: tensor([0.8796])\n",
            "Step: 206,  Pearson: tensor([0.8992])\n",
            "Step: 207,  Pearson: tensor([0.7867])\n",
            "Step: 208,  Pearson: tensor([0.8227])\n",
            "Step: 209,  Pearson: tensor([0.8827])\n",
            "Step: 210,  Pearson: tensor([0.8690])\n",
            "Step: 211,  Pearson: tensor([0.8827])\n",
            "Step: 212,  Pearson: tensor([0.8657])\n",
            "Step: 213,  Pearson: tensor([0.7591])\n",
            "Step: 214,  Pearson: tensor([0.7703])\n",
            "Step: 215,  Pearson: tensor([0.7736])\n",
            "Step: 216,  Pearson: tensor([0.7804])\n",
            "Step: 217,  Pearson: tensor([0.8259])\n",
            "Step: 218,  Pearson: tensor([0.7334])\n",
            "Step: 219,  Pearson: tensor([0.8795])\n",
            "Step: 220,  Pearson: tensor([0.7638])\n",
            "Step: 221,  Pearson: tensor([0.9704])\n",
            "Step: 222,  Pearson: tensor([0.8404])\n",
            "Step: 223,  Pearson: tensor([0.9178])\n",
            "Step: 224,  Pearson: tensor([0.8907])\n",
            "Step: 225,  Pearson: tensor([0.9131])\n",
            "Step: 226,  Pearson: tensor([0.7185])\n",
            "Step: 227,  Pearson: tensor([0.7985])\n",
            "Epoch 1 Valid Loss : 0.07300435295001718 Valid Pearsonr : tensor([0.8412]) ValidF1 : 0.14472177696359056\n",
            "*****Epoch 1 Valid Finish*****\n",
            "\n",
            "SAVING EPOCH 1 ...\n",
            "****** STARTING TO TRAIN EPOCH #2 ******\n",
            "Epoch: 2, Step : 10, LR : 5.101498308361528e-06, Avg Loss : 0.0467\n",
            "Epoch: 2, Step : 20, LR : 5.077332044465926e-06, Avg Loss : 0.0272\n",
            "Epoch: 2, Step : 30, LR : 5.0531657805703235e-06, Avg Loss : 0.0261\n",
            "Epoch: 2, Step : 40, LR : 5.028999516674723e-06, Avg Loss : 0.0324\n",
            "Epoch: 2, Step : 50, LR : 5.004833252779121e-06, Avg Loss : 0.0249\n",
            "Epoch: 2, Step : 60, LR : 4.9806669888835194e-06, Avg Loss : 0.0287\n",
            "Epoch: 2, Step : 70, LR : 4.956500724987917e-06, Avg Loss : 0.0240\n",
            "Epoch: 2, Step : 80, LR : 4.932334461092315e-06, Avg Loss : 0.0267\n",
            "Epoch: 2, Step : 90, LR : 4.908168197196714e-06, Avg Loss : 0.0246\n",
            "Epoch: 2, Step : 100, LR : 4.884001933301112e-06, Avg Loss : 0.0234\n",
            "Epoch: 2, Step : 110, LR : 4.85983566940551e-06, Avg Loss : 0.0373\n",
            "Epoch: 2, Step : 120, LR : 4.835669405509909e-06, Avg Loss : 0.0305\n",
            "Epoch: 2, Step : 130, LR : 4.811503141614307e-06, Avg Loss : 0.0326\n",
            "Epoch: 2, Step : 140, LR : 4.7873368777187055e-06, Avg Loss : 0.0280\n",
            "Epoch: 2, Step : 150, LR : 4.763170613823103e-06, Avg Loss : 0.0231\n",
            "Epoch: 2, Step : 160, LR : 4.739004349927502e-06, Avg Loss : 0.0280\n",
            "Epoch: 2, Step : 170, LR : 4.7148380860319e-06, Avg Loss : 0.0331\n",
            "Epoch: 2, Step : 180, LR : 4.690671822136298e-06, Avg Loss : 0.0269\n",
            "Epoch: 2, Step : 190, LR : 4.6665055582406964e-06, Avg Loss : 0.0325\n",
            "Epoch: 2, Step : 200, LR : 4.642339294345095e-06, Avg Loss : 0.0261\n",
            "Epoch: 2, Step : 210, LR : 4.618173030449492e-06, Avg Loss : 0.0227\n",
            "Epoch: 2, Step : 220, LR : 4.5940067665538915e-06, Avg Loss : 0.0287\n",
            "Epoch: 2, Step : 230, LR : 4.569840502658289e-06, Avg Loss : 0.0229\n",
            "Epoch: 2, Step : 240, LR : 4.545674238762688e-06, Avg Loss : 0.0355\n",
            "Epoch: 2, Step : 250, LR : 4.521507974867086e-06, Avg Loss : 0.0272\n",
            "Epoch: 2, Step : 260, LR : 4.497341710971484e-06, Avg Loss : 0.0325\n",
            "Epoch: 2, Step : 270, LR : 4.4731754470758825e-06, Avg Loss : 0.0405\n",
            "Epoch: 2, Step : 280, LR : 4.449009183180281e-06, Avg Loss : 0.0318\n",
            "Epoch: 2, Step : 290, LR : 4.424842919284678e-06, Avg Loss : 0.0324\n",
            "Epoch: 2, Step : 300, LR : 4.4006766553890776e-06, Avg Loss : 0.0234\n",
            "Epoch: 2, Step : 310, LR : 4.376510391493475e-06, Avg Loss : 0.0390\n",
            "Epoch: 2, Step : 320, LR : 4.352344127597874e-06, Avg Loss : 0.0332\n",
            "Epoch: 2, Step : 330, LR : 4.328177863702272e-06, Avg Loss : 0.0336\n",
            "Epoch: 2, Step : 340, LR : 4.30401159980667e-06, Avg Loss : 0.0241\n",
            "Epoch: 2, Step : 350, LR : 4.2798453359110685e-06, Avg Loss : 0.0274\n",
            "Epoch: 2, Step : 360, LR : 4.255679072015467e-06, Avg Loss : 0.0252\n",
            "Epoch: 2, Step : 370, LR : 4.231512808119864e-06, Avg Loss : 0.0246\n",
            "Epoch: 2, Step : 380, LR : 4.207346544224264e-06, Avg Loss : 0.0223\n",
            "Epoch: 2, Step : 390, LR : 4.183180280328661e-06, Avg Loss : 0.0292\n",
            "Epoch: 2, Step : 400, LR : 4.15901401643306e-06, Avg Loss : 0.0288\n",
            "Epoch: 2, Step : 410, LR : 4.134847752537458e-06, Avg Loss : 0.0217\n",
            "Epoch: 2, Step : 420, LR : 4.110681488641856e-06, Avg Loss : 0.0354\n",
            "Epoch: 2, Step : 430, LR : 4.086515224746255e-06, Avg Loss : 0.0227\n",
            "Epoch: 2, Step : 440, LR : 4.062348960850653e-06, Avg Loss : 0.0361\n",
            "Epoch: 2, Step : 450, LR : 4.0381826969550505e-06, Avg Loss : 0.0404\n",
            "Epoch: 2, Step : 460, LR : 4.01401643305945e-06, Avg Loss : 0.0299\n",
            "Epoch: 2, Step : 470, LR : 3.989850169163847e-06, Avg Loss : 0.0311\n",
            "Epoch: 2, Step : 480, LR : 3.965683905268246e-06, Avg Loss : 0.0244\n",
            "Epoch: 2, Step : 490, LR : 3.941517641372644e-06, Avg Loss : 0.0288\n",
            "Epoch: 2, Step : 500, LR : 3.917351377477042e-06, Avg Loss : 0.0210\n",
            "Epoch: 2, Step : 510, LR : 3.893185113581441e-06, Avg Loss : 0.0370\n",
            "Epoch: 2, Step : 520, LR : 3.869018849685839e-06, Avg Loss : 0.0264\n",
            "Epoch: 2, Step : 530, LR : 3.8448525857902365e-06, Avg Loss : 0.0243\n",
            "Epoch: 2, Step : 540, LR : 3.820686321894636e-06, Avg Loss : 0.0261\n",
            "Epoch: 2, Step : 550, LR : 3.7965200579990337e-06, Avg Loss : 0.0251\n",
            "Epoch: 2, Step : 560, LR : 3.772353794103432e-06, Avg Loss : 0.0299\n",
            "Epoch: 2, Step : 570, LR : 3.7481875302078304e-06, Avg Loss : 0.0317\n",
            "Epoch: 2, Step : 580, LR : 3.7240212663122283e-06, Avg Loss : 0.0311\n",
            "Epoch: 2, Step : 590, LR : 3.6998550024166267e-06, Avg Loss : 0.0321\n",
            "Epoch: 2, Step : 600, LR : 3.675688738521025e-06, Avg Loss : 0.0305\n",
            "Epoch: 2, Step : 610, LR : 3.651522474625423e-06, Avg Loss : 0.0357\n",
            "Epoch: 2, Step : 620, LR : 3.6273562107298218e-06, Avg Loss : 0.0294\n",
            "Epoch: 2, Step : 630, LR : 3.6031899468342197e-06, Avg Loss : 0.0292\n",
            "Epoch: 2, Step : 640, LR : 3.579023682938618e-06, Avg Loss : 0.0295\n",
            "Epoch: 2, Step : 650, LR : 3.5548574190430164e-06, Avg Loss : 0.0363\n",
            "Epoch: 2, Step : 660, LR : 3.5306911551474144e-06, Avg Loss : 0.0223\n",
            "Epoch: 2, Step : 670, LR : 3.506524891251813e-06, Avg Loss : 0.0297\n",
            "Epoch: 2, Step : 680, LR : 3.482358627356211e-06, Avg Loss : 0.0367\n",
            "Epoch: 2, Step : 690, LR : 3.458192363460609e-06, Avg Loss : 0.0268\n",
            "Epoch: 2, Step : 700, LR : 3.434026099565008e-06, Avg Loss : 0.0339\n",
            "Epoch: 2, Step : 710, LR : 3.4098598356694057e-06, Avg Loss : 0.0338\n",
            "Epoch: 2, Step : 720, LR : 3.385693571773804e-06, Avg Loss : 0.0223\n",
            "Epoch: 2, Step : 730, LR : 3.3615273078782025e-06, Avg Loss : 0.0269\n",
            "Epoch: 2, Step : 740, LR : 3.3373610439826004e-06, Avg Loss : 0.0277\n",
            "Epoch: 2, Step : 750, LR : 3.313194780086999e-06, Avg Loss : 0.0289\n",
            "Epoch: 2, Step : 760, LR : 3.289028516191397e-06, Avg Loss : 0.0229\n",
            "Epoch: 2, Step : 770, LR : 3.264862252295795e-06, Avg Loss : 0.0239\n",
            "Epoch: 2, Step : 780, LR : 3.240695988400194e-06, Avg Loss : 0.0317\n",
            "Epoch: 2, Step : 790, LR : 3.216529724504592e-06, Avg Loss : 0.0312\n",
            "Epoch: 2, Step : 800, LR : 3.1923634606089906e-06, Avg Loss : 0.0234\n",
            "Epoch: 2, Step : 810, LR : 3.1681971967133885e-06, Avg Loss : 0.0385\n",
            "Epoch: 2, Step : 820, LR : 3.1440309328177865e-06, Avg Loss : 0.0328\n",
            "Epoch: 2, Step : 830, LR : 3.1198646689221852e-06, Avg Loss : 0.0306\n",
            "Epoch: 2, Step : 840, LR : 3.095698405026583e-06, Avg Loss : 0.0269\n",
            "Epoch: 2, Step : 850, LR : 3.071532141130981e-06, Avg Loss : 0.0348\n",
            "Epoch: 2, Step : 860, LR : 3.04736587723538e-06, Avg Loss : 0.0240\n",
            "Epoch: 2, Step : 870, LR : 3.023199613339778e-06, Avg Loss : 0.0285\n",
            "Epoch: 2, Step : 880, LR : 2.9990333494441758e-06, Avg Loss : 0.0297\n",
            "Epoch: 2, Step : 890, LR : 2.9748670855485746e-06, Avg Loss : 0.0382\n",
            "Epoch: 2, Step : 900, LR : 2.9507008216529725e-06, Avg Loss : 0.0359\n",
            "Epoch: 2, Step : 910, LR : 2.9265345577573713e-06, Avg Loss : 0.0224\n",
            "Epoch: 2, Step : 920, LR : 2.9023682938617692e-06, Avg Loss : 0.0340\n",
            "Epoch: 2, Step : 930, LR : 2.878202029966167e-06, Avg Loss : 0.0471\n",
            "Epoch: 2, Step : 940, LR : 2.854035766070566e-06, Avg Loss : 0.0250\n",
            "Epoch: 2, Step : 950, LR : 2.829869502174964e-06, Avg Loss : 0.0236\n",
            "Epoch: 2, Step : 960, LR : 2.805703238279362e-06, Avg Loss : 0.0243\n",
            "Epoch: 2, Step : 970, LR : 2.7815369743837606e-06, Avg Loss : 0.0291\n",
            "Epoch: 2, Step : 980, LR : 2.7573707104881585e-06, Avg Loss : 0.0343\n",
            "Epoch: 2, Step : 990, LR : 2.7332044465925573e-06, Avg Loss : 0.0293\n",
            "Epoch: 2, Step : 1000, LR : 2.7090381826969553e-06, Avg Loss : 0.0268\n",
            "Epoch: 2, Step : 1010, LR : 2.684871918801353e-06, Avg Loss : 0.0358\n",
            "Epoch: 2, Step : 1020, LR : 2.660705654905752e-06, Avg Loss : 0.0264\n",
            "Epoch: 2, Step : 1030, LR : 2.63653939101015e-06, Avg Loss : 0.0298\n",
            "Epoch: 2, Step : 1040, LR : 2.612373127114548e-06, Avg Loss : 0.0272\n",
            "Epoch: 2, Step : 1050, LR : 2.5882068632189467e-06, Avg Loss : 0.0308\n",
            "Epoch: 2, Step : 1060, LR : 2.5640405993233446e-06, Avg Loss : 0.0257\n",
            "Epoch 2 Total Mean Loss : 0.0295\n",
            "*****Epoch 2 Train Finish*****\n",
            "\n",
            "*****Epoch 2 Valid Start*****\n",
            "Step: 0,  Pearson: tensor([0.7644])\n",
            "Step: 1,  Pearson: tensor([0.8293])\n",
            "Step: 2,  Pearson: tensor([0.9279])\n",
            "Step: 3,  Pearson: tensor([0.8983])\n",
            "Step: 4,  Pearson: tensor([0.9462])\n",
            "Step: 5,  Pearson: tensor([0.8843])\n",
            "Step: 6,  Pearson: tensor([0.7567])\n",
            "Step: 7,  Pearson: tensor([0.9208])\n",
            "Step: 8,  Pearson: tensor([0.8448])\n",
            "Step: 9,  Pearson: tensor([0.7866])\n",
            "Step: 10,  Pearson: tensor([0.8951])\n",
            "Step: 11,  Pearson: tensor([0.7771])\n",
            "Step: 12,  Pearson: tensor([0.8223])\n",
            "Step: 13,  Pearson: tensor([0.6528])\n",
            "Step: 14,  Pearson: tensor([0.6439])\n",
            "Step: 15,  Pearson: tensor([0.7010])\n",
            "Step: 16,  Pearson: tensor([0.6477])\n",
            "Step: 17,  Pearson: tensor([0.8512])\n",
            "Step: 18,  Pearson: tensor([0.8624])\n",
            "Step: 19,  Pearson: tensor([0.7275])\n",
            "Step: 20,  Pearson: tensor([0.7838])\n",
            "Step: 21,  Pearson: tensor([0.8140])\n",
            "Step: 22,  Pearson: tensor([0.8141])\n",
            "Step: 23,  Pearson: tensor([0.8118])\n",
            "Step: 24,  Pearson: tensor([0.8661])\n",
            "Step: 25,  Pearson: tensor([0.8281])\n",
            "Step: 26,  Pearson: tensor([0.9069])\n",
            "Step: 27,  Pearson: tensor([0.7283])\n",
            "Step: 28,  Pearson: tensor([0.8998])\n",
            "Step: 29,  Pearson: tensor([0.7271])\n",
            "Step: 30,  Pearson: tensor([0.8613])\n",
            "Step: 31,  Pearson: tensor([0.9111])\n",
            "Step: 32,  Pearson: tensor([0.8525])\n",
            "Step: 33,  Pearson: tensor([0.9643])\n",
            "Step: 34,  Pearson: tensor([0.9005])\n",
            "Step: 35,  Pearson: tensor([0.8329])\n",
            "Step: 36,  Pearson: tensor([0.9234])\n",
            "Step: 37,  Pearson: tensor([0.9302])\n",
            "Step: 38,  Pearson: tensor([0.8666])\n",
            "Step: 39,  Pearson: tensor([0.9543])\n",
            "Step: 40,  Pearson: tensor([0.7790])\n",
            "Step: 41,  Pearson: tensor([0.7285])\n",
            "Step: 42,  Pearson: tensor([0.7988])\n",
            "Step: 43,  Pearson: tensor([0.8725])\n",
            "Step: 44,  Pearson: tensor([0.7783])\n",
            "Step: 45,  Pearson: tensor([0.9070])\n",
            "Step: 46,  Pearson: tensor([0.8137])\n",
            "Step: 47,  Pearson: tensor([0.8233])\n",
            "Step: 48,  Pearson: tensor([0.8315])\n",
            "Step: 49,  Pearson: tensor([0.8379])\n",
            "Step: 50,  Pearson: tensor([0.6498])\n",
            "Step: 51,  Pearson: tensor([0.7911])\n",
            "Step: 52,  Pearson: tensor([0.9010])\n",
            "Step: 53,  Pearson: tensor([0.8015])\n",
            "Step: 54,  Pearson: tensor([0.8858])\n",
            "Step: 55,  Pearson: tensor([0.9446])\n",
            "Step: 56,  Pearson: tensor([0.7802])\n",
            "Step: 57,  Pearson: tensor([0.8879])\n",
            "Step: 58,  Pearson: tensor([0.7476])\n",
            "Step: 59,  Pearson: tensor([0.8172])\n",
            "Step: 60,  Pearson: tensor([0.8403])\n",
            "Step: 61,  Pearson: tensor([0.8335])\n",
            "Step: 62,  Pearson: tensor([0.8151])\n",
            "Step: 63,  Pearson: tensor([0.9188])\n",
            "Step: 64,  Pearson: tensor([0.7849])\n",
            "Step: 65,  Pearson: tensor([0.8538])\n",
            "Step: 66,  Pearson: tensor([0.8857])\n",
            "Step: 67,  Pearson: tensor([0.8146])\n",
            "Step: 68,  Pearson: tensor([0.6507])\n",
            "Step: 69,  Pearson: tensor([0.8638])\n",
            "Step: 70,  Pearson: tensor([0.8375])\n",
            "Step: 71,  Pearson: tensor([0.8185])\n",
            "Step: 72,  Pearson: tensor([0.7331])\n",
            "Step: 73,  Pearson: tensor([0.8541])\n",
            "Step: 74,  Pearson: tensor([0.7646])\n",
            "Step: 75,  Pearson: tensor([0.8675])\n",
            "Step: 76,  Pearson: tensor([0.8610])\n",
            "Step: 77,  Pearson: tensor([0.7790])\n",
            "Step: 78,  Pearson: tensor([0.8248])\n",
            "Step: 79,  Pearson: tensor([0.8705])\n",
            "Step: 80,  Pearson: tensor([0.7566])\n",
            "Step: 81,  Pearson: tensor([0.7572])\n",
            "Step: 82,  Pearson: tensor([0.7589])\n",
            "Step: 83,  Pearson: tensor([0.9249])\n",
            "Step: 84,  Pearson: tensor([0.9023])\n",
            "Step: 85,  Pearson: tensor([0.8602])\n",
            "Step: 86,  Pearson: tensor([0.8512])\n",
            "Step: 87,  Pearson: tensor([0.8302])\n",
            "Step: 88,  Pearson: tensor([0.8284])\n",
            "Step: 89,  Pearson: tensor([0.8521])\n",
            "Step: 90,  Pearson: tensor([0.9068])\n",
            "Step: 91,  Pearson: tensor([0.9102])\n",
            "Step: 92,  Pearson: tensor([0.7796])\n",
            "Step: 93,  Pearson: tensor([0.8448])\n",
            "Step: 94,  Pearson: tensor([0.8754])\n",
            "Step: 95,  Pearson: tensor([0.8097])\n",
            "Step: 96,  Pearson: tensor([0.8495])\n",
            "Step: 97,  Pearson: tensor([0.7753])\n",
            "Step: 98,  Pearson: tensor([0.8259])\n",
            "Step: 99,  Pearson: tensor([0.7815])\n",
            "Step: 100,  Pearson: tensor([0.8844])\n",
            "Step: 101,  Pearson: tensor([0.8487])\n",
            "Step: 102,  Pearson: tensor([0.9618])\n",
            "Step: 103,  Pearson: tensor([0.8694])\n",
            "Step: 104,  Pearson: tensor([0.8121])\n",
            "Step: 105,  Pearson: tensor([0.8916])\n",
            "Step: 106,  Pearson: tensor([0.8618])\n",
            "Step: 107,  Pearson: tensor([0.8487])\n",
            "Step: 108,  Pearson: tensor([0.8994])\n",
            "Step: 109,  Pearson: tensor([0.8620])\n",
            "Step: 110,  Pearson: tensor([0.9117])\n",
            "Step: 111,  Pearson: tensor([0.8770])\n",
            "Step: 112,  Pearson: tensor([0.9130])\n",
            "Step: 113,  Pearson: tensor([0.7879])\n",
            "Step: 114,  Pearson: tensor([0.8403])\n",
            "Step: 115,  Pearson: tensor([0.8003])\n",
            "Step: 116,  Pearson: tensor([0.7342])\n",
            "Step: 117,  Pearson: tensor([0.7741])\n",
            "Step: 118,  Pearson: tensor([0.9371])\n",
            "Step: 119,  Pearson: tensor([0.8662])\n",
            "Step: 120,  Pearson: tensor([0.8753])\n",
            "Step: 121,  Pearson: tensor([0.7763])\n",
            "Step: 122,  Pearson: tensor([0.9596])\n",
            "Step: 123,  Pearson: tensor([0.7246])\n",
            "Step: 124,  Pearson: tensor([0.9272])\n",
            "Step: 125,  Pearson: tensor([0.8415])\n",
            "Step: 126,  Pearson: tensor([0.8631])\n",
            "Step: 127,  Pearson: tensor([0.8902])\n",
            "Step: 128,  Pearson: tensor([0.9579])\n",
            "Step: 129,  Pearson: tensor([0.8766])\n",
            "Step: 130,  Pearson: tensor([0.7497])\n",
            "Step: 131,  Pearson: tensor([0.8663])\n",
            "Step: 132,  Pearson: tensor([0.8068])\n",
            "Step: 133,  Pearson: tensor([0.8388])\n",
            "Step: 134,  Pearson: tensor([0.7597])\n",
            "Step: 135,  Pearson: tensor([0.8263])\n",
            "Step: 136,  Pearson: tensor([0.7284])\n",
            "Step: 137,  Pearson: tensor([0.9463])\n",
            "Step: 138,  Pearson: tensor([0.7330])\n",
            "Step: 139,  Pearson: tensor([0.9070])\n",
            "Step: 140,  Pearson: tensor([0.8626])\n",
            "Step: 141,  Pearson: tensor([0.7974])\n",
            "Step: 142,  Pearson: tensor([0.8589])\n",
            "Step: 143,  Pearson: tensor([0.8395])\n",
            "Step: 144,  Pearson: tensor([0.8859])\n",
            "Step: 145,  Pearson: tensor([0.9136])\n",
            "Step: 146,  Pearson: tensor([0.8055])\n",
            "Step: 147,  Pearson: tensor([0.8684])\n",
            "Step: 148,  Pearson: tensor([0.8266])\n",
            "Step: 149,  Pearson: tensor([0.8747])\n",
            "Step: 150,  Pearson: tensor([0.8807])\n",
            "Step: 151,  Pearson: tensor([0.9262])\n",
            "Step: 152,  Pearson: tensor([0.8793])\n",
            "Step: 153,  Pearson: tensor([0.7061])\n",
            "Step: 154,  Pearson: tensor([0.8427])\n",
            "Step: 155,  Pearson: tensor([0.8869])\n",
            "Step: 156,  Pearson: tensor([0.8714])\n",
            "Step: 157,  Pearson: tensor([0.9345])\n",
            "Step: 158,  Pearson: tensor([0.8693])\n",
            "Step: 159,  Pearson: tensor([0.8902])\n",
            "Step: 160,  Pearson: tensor([0.8753])\n",
            "Step: 161,  Pearson: tensor([0.9230])\n",
            "Step: 162,  Pearson: tensor([0.7251])\n",
            "Step: 163,  Pearson: tensor([0.8065])\n",
            "Step: 164,  Pearson: tensor([0.9077])\n",
            "Step: 165,  Pearson: tensor([0.9251])\n",
            "Step: 166,  Pearson: tensor([0.8993])\n",
            "Step: 167,  Pearson: tensor([0.8027])\n",
            "Step: 168,  Pearson: tensor([0.7954])\n",
            "Step: 169,  Pearson: tensor([0.8579])\n",
            "Step: 170,  Pearson: tensor([0.8703])\n",
            "Step: 171,  Pearson: tensor([0.9040])\n",
            "Step: 172,  Pearson: tensor([0.9467])\n",
            "Step: 173,  Pearson: tensor([0.7988])\n",
            "Step: 174,  Pearson: tensor([0.9195])\n",
            "Step: 175,  Pearson: tensor([0.6854])\n",
            "Step: 176,  Pearson: tensor([0.8884])\n",
            "Step: 177,  Pearson: tensor([0.8950])\n",
            "Step: 178,  Pearson: tensor([0.8281])\n",
            "Step: 179,  Pearson: tensor([0.7166])\n",
            "Step: 180,  Pearson: tensor([0.7908])\n",
            "Step: 181,  Pearson: tensor([0.8343])\n",
            "Step: 182,  Pearson: tensor([0.6512])\n",
            "Step: 183,  Pearson: tensor([0.8680])\n",
            "Step: 184,  Pearson: tensor([0.7760])\n",
            "Step: 185,  Pearson: tensor([0.8743])\n",
            "Step: 186,  Pearson: tensor([0.8228])\n",
            "Step: 187,  Pearson: tensor([0.8515])\n",
            "Step: 188,  Pearson: tensor([0.8235])\n",
            "Step: 189,  Pearson: tensor([0.8034])\n",
            "Step: 190,  Pearson: tensor([0.8322])\n",
            "Step: 191,  Pearson: tensor([0.8083])\n",
            "Step: 192,  Pearson: tensor([0.7595])\n",
            "Step: 193,  Pearson: tensor([0.8072])\n",
            "Step: 194,  Pearson: tensor([0.8604])\n",
            "Step: 195,  Pearson: tensor([0.8743])\n",
            "Step: 196,  Pearson: tensor([0.8614])\n",
            "Step: 197,  Pearson: tensor([0.8423])\n",
            "Step: 198,  Pearson: tensor([0.8306])\n",
            "Step: 199,  Pearson: tensor([0.9344])\n",
            "Step: 200,  Pearson: tensor([0.8394])\n",
            "Step: 201,  Pearson: tensor([0.8622])\n",
            "Step: 202,  Pearson: tensor([0.8636])\n",
            "Step: 203,  Pearson: tensor([0.9011])\n",
            "Step: 204,  Pearson: tensor([0.9667])\n",
            "Step: 205,  Pearson: tensor([0.8714])\n",
            "Step: 206,  Pearson: tensor([0.8887])\n",
            "Step: 207,  Pearson: tensor([0.7807])\n",
            "Step: 208,  Pearson: tensor([0.8046])\n",
            "Step: 209,  Pearson: tensor([0.8606])\n",
            "Step: 210,  Pearson: tensor([0.8849])\n",
            "Step: 211,  Pearson: tensor([0.8754])\n",
            "Step: 212,  Pearson: tensor([0.8476])\n",
            "Step: 213,  Pearson: tensor([0.7246])\n",
            "Step: 214,  Pearson: tensor([0.7487])\n",
            "Step: 215,  Pearson: tensor([0.7824])\n",
            "Step: 216,  Pearson: tensor([0.7558])\n",
            "Step: 217,  Pearson: tensor([0.8206])\n",
            "Step: 218,  Pearson: tensor([0.7679])\n",
            "Step: 219,  Pearson: tensor([0.8947])\n",
            "Step: 220,  Pearson: tensor([0.7537])\n",
            "Step: 221,  Pearson: tensor([0.9614])\n",
            "Step: 222,  Pearson: tensor([0.8254])\n",
            "Step: 223,  Pearson: tensor([0.9189])\n",
            "Step: 224,  Pearson: tensor([0.8786])\n",
            "Step: 225,  Pearson: tensor([0.9125])\n",
            "Step: 226,  Pearson: tensor([0.7114])\n",
            "Step: 227,  Pearson: tensor([0.7736])\n",
            "Epoch 2 Valid Loss : 0.07393912949779055 Valid Pearsonr : tensor([0.8387]) ValidF1 : 0.14472177696359056\n",
            "*****Epoch 2 Valid Finish*****\n",
            "\n",
            "SAVING EPOCH 2 ...\n",
            "****** STARTING TO TRAIN EPOCH #3 ******\n",
            "Epoch: 3, Step : 10, LR : 2.537457709038183e-06, Avg Loss : 0.0195\n",
            "Epoch: 3, Step : 20, LR : 2.513291445142581e-06, Avg Loss : 0.0190\n",
            "Epoch: 3, Step : 30, LR : 2.4891251812469793e-06, Avg Loss : 0.0224\n",
            "Epoch: 3, Step : 40, LR : 2.4649589173513777e-06, Avg Loss : 0.0162\n",
            "Epoch: 3, Step : 50, LR : 2.440792653455776e-06, Avg Loss : 0.0243\n",
            "Epoch: 3, Step : 60, LR : 2.416626389560174e-06, Avg Loss : 0.0198\n",
            "Epoch: 3, Step : 70, LR : 2.3924601256645724e-06, Avg Loss : 0.0185\n",
            "Epoch: 3, Step : 80, LR : 2.3682938617689707e-06, Avg Loss : 0.0204\n",
            "Epoch: 3, Step : 90, LR : 2.344127597873369e-06, Avg Loss : 0.0181\n",
            "Epoch: 3, Step : 100, LR : 2.319961333977767e-06, Avg Loss : 0.0188\n",
            "Epoch: 3, Step : 110, LR : 2.2957950700821654e-06, Avg Loss : 0.0199\n",
            "Epoch: 3, Step : 120, LR : 2.2716288061865637e-06, Avg Loss : 0.0228\n",
            "Epoch: 3, Step : 130, LR : 2.247462542290962e-06, Avg Loss : 0.0200\n",
            "Epoch: 3, Step : 140, LR : 2.22329627839536e-06, Avg Loss : 0.0173\n",
            "Epoch: 3, Step : 150, LR : 2.1991300144997584e-06, Avg Loss : 0.0224\n",
            "Epoch: 3, Step : 160, LR : 2.1749637506041568e-06, Avg Loss : 0.0137\n",
            "Epoch: 3, Step : 170, LR : 2.150797486708555e-06, Avg Loss : 0.0169\n",
            "Epoch: 3, Step : 180, LR : 2.126631222812953e-06, Avg Loss : 0.0168\n",
            "Epoch: 3, Step : 190, LR : 2.1024649589173514e-06, Avg Loss : 0.0160\n",
            "Epoch: 3, Step : 200, LR : 2.07829869502175e-06, Avg Loss : 0.0136\n",
            "Epoch: 3, Step : 210, LR : 2.054132431126148e-06, Avg Loss : 0.0155\n",
            "Epoch: 3, Step : 220, LR : 2.029966167230546e-06, Avg Loss : 0.0209\n",
            "Epoch: 3, Step : 230, LR : 2.0057999033349445e-06, Avg Loss : 0.0201\n",
            "Epoch: 3, Step : 240, LR : 1.981633639439343e-06, Avg Loss : 0.0163\n",
            "Epoch: 3, Step : 250, LR : 1.957467375543741e-06, Avg Loss : 0.0183\n",
            "Epoch: 3, Step : 260, LR : 1.933301111648139e-06, Avg Loss : 0.0202\n",
            "Epoch: 3, Step : 270, LR : 1.9091348477525375e-06, Avg Loss : 0.0176\n",
            "Epoch: 3, Step : 280, LR : 1.8849685838569358e-06, Avg Loss : 0.0236\n",
            "Epoch: 3, Step : 290, LR : 1.8608023199613342e-06, Avg Loss : 0.0162\n",
            "Epoch: 3, Step : 300, LR : 1.8366360560657324e-06, Avg Loss : 0.0144\n",
            "Epoch: 3, Step : 310, LR : 1.8124697921701307e-06, Avg Loss : 0.0188\n",
            "Epoch: 3, Step : 320, LR : 1.7883035282745289e-06, Avg Loss : 0.0210\n",
            "Epoch: 3, Step : 330, LR : 1.7641372643789272e-06, Avg Loss : 0.0221\n",
            "Epoch: 3, Step : 340, LR : 1.7399710004833254e-06, Avg Loss : 0.0185\n",
            "Epoch: 3, Step : 350, LR : 1.7158047365877237e-06, Avg Loss : 0.0202\n",
            "Epoch: 3, Step : 360, LR : 1.691638472692122e-06, Avg Loss : 0.0180\n",
            "Epoch: 3, Step : 370, LR : 1.6674722087965202e-06, Avg Loss : 0.0155\n",
            "Epoch: 3, Step : 380, LR : 1.6433059449009184e-06, Avg Loss : 0.0205\n",
            "Epoch: 3, Step : 390, LR : 1.6191396810053168e-06, Avg Loss : 0.0195\n",
            "Epoch: 3, Step : 400, LR : 1.5949734171097151e-06, Avg Loss : 0.0221\n",
            "Epoch: 3, Step : 410, LR : 1.570807153214113e-06, Avg Loss : 0.0179\n",
            "Epoch: 3, Step : 420, LR : 1.5466408893185114e-06, Avg Loss : 0.0126\n",
            "Epoch: 3, Step : 430, LR : 1.5224746254229098e-06, Avg Loss : 0.0203\n",
            "Epoch: 3, Step : 440, LR : 1.4983083615273081e-06, Avg Loss : 0.0248\n",
            "Epoch: 3, Step : 450, LR : 1.474142097631706e-06, Avg Loss : 0.0236\n",
            "Epoch: 3, Step : 460, LR : 1.4499758337361044e-06, Avg Loss : 0.0135\n",
            "Epoch: 3, Step : 470, LR : 1.4258095698405028e-06, Avg Loss : 0.0201\n",
            "Epoch: 3, Step : 480, LR : 1.4016433059449012e-06, Avg Loss : 0.0176\n",
            "Epoch: 3, Step : 490, LR : 1.377477042049299e-06, Avg Loss : 0.0184\n",
            "Epoch: 3, Step : 500, LR : 1.3533107781536975e-06, Avg Loss : 0.0235\n",
            "Epoch: 3, Step : 510, LR : 1.3291445142580958e-06, Avg Loss : 0.0239\n",
            "Epoch: 3, Step : 520, LR : 1.3049782503624942e-06, Avg Loss : 0.0195\n",
            "Epoch: 3, Step : 530, LR : 1.2808119864668921e-06, Avg Loss : 0.0178\n",
            "Epoch: 3, Step : 540, LR : 1.2566457225712905e-06, Avg Loss : 0.0251\n",
            "Epoch: 3, Step : 550, LR : 1.2324794586756889e-06, Avg Loss : 0.0237\n",
            "Epoch: 3, Step : 560, LR : 1.208313194780087e-06, Avg Loss : 0.0195\n",
            "Epoch: 3, Step : 570, LR : 1.1841469308844854e-06, Avg Loss : 0.0252\n",
            "Epoch: 3, Step : 580, LR : 1.1599806669888835e-06, Avg Loss : 0.0296\n",
            "Epoch: 3, Step : 590, LR : 1.1358144030932819e-06, Avg Loss : 0.0170\n",
            "Epoch: 3, Step : 600, LR : 1.11164813919768e-06, Avg Loss : 0.0246\n",
            "Epoch: 3, Step : 610, LR : 1.0874818753020784e-06, Avg Loss : 0.0182\n",
            "Epoch: 3, Step : 620, LR : 1.0633156114064765e-06, Avg Loss : 0.0149\n",
            "Epoch: 3, Step : 630, LR : 1.039149347510875e-06, Avg Loss : 0.0185\n",
            "Epoch: 3, Step : 640, LR : 1.014983083615273e-06, Avg Loss : 0.0169\n",
            "Epoch: 3, Step : 650, LR : 9.908168197196714e-07, Avg Loss : 0.0152\n",
            "Epoch: 3, Step : 660, LR : 9.666505558240696e-07, Avg Loss : 0.0141\n",
            "Epoch: 3, Step : 670, LR : 9.424842919284679e-07, Avg Loss : 0.0177\n",
            "Epoch: 3, Step : 680, LR : 9.183180280328662e-07, Avg Loss : 0.0166\n",
            "Epoch: 3, Step : 690, LR : 8.941517641372644e-07, Avg Loss : 0.0168\n",
            "Epoch: 3, Step : 700, LR : 8.699855002416627e-07, Avg Loss : 0.0191\n",
            "Epoch: 3, Step : 710, LR : 8.45819236346061e-07, Avg Loss : 0.0168\n",
            "Epoch: 3, Step : 720, LR : 8.216529724504592e-07, Avg Loss : 0.0163\n",
            "Epoch: 3, Step : 730, LR : 7.974867085548576e-07, Avg Loss : 0.0183\n",
            "Epoch: 3, Step : 740, LR : 7.733204446592557e-07, Avg Loss : 0.0147\n",
            "Epoch: 3, Step : 750, LR : 7.491541807636541e-07, Avg Loss : 0.0211\n",
            "Epoch: 3, Step : 760, LR : 7.249879168680522e-07, Avg Loss : 0.0173\n",
            "Epoch: 3, Step : 770, LR : 7.008216529724506e-07, Avg Loss : 0.0230\n",
            "Epoch: 3, Step : 780, LR : 6.766553890768487e-07, Avg Loss : 0.0208\n",
            "Epoch: 3, Step : 790, LR : 6.524891251812471e-07, Avg Loss : 0.0195\n",
            "Epoch: 3, Step : 800, LR : 6.283228612856452e-07, Avg Loss : 0.0152\n",
            "Epoch: 3, Step : 810, LR : 6.041565973900435e-07, Avg Loss : 0.0139\n",
            "Epoch: 3, Step : 820, LR : 5.799903334944418e-07, Avg Loss : 0.0169\n",
            "Epoch: 3, Step : 830, LR : 5.5582406959884e-07, Avg Loss : 0.0162\n",
            "Epoch: 3, Step : 840, LR : 5.316578057032383e-07, Avg Loss : 0.0172\n",
            "Epoch: 3, Step : 850, LR : 5.074915418076365e-07, Avg Loss : 0.0157\n",
            "Epoch: 3, Step : 860, LR : 4.833252779120348e-07, Avg Loss : 0.0260\n",
            "Epoch: 3, Step : 870, LR : 4.591590140164331e-07, Avg Loss : 0.0183\n",
            "Epoch: 3, Step : 880, LR : 4.3499275012083134e-07, Avg Loss : 0.0161\n",
            "Epoch: 3, Step : 890, LR : 4.108264862252296e-07, Avg Loss : 0.0169\n",
            "Epoch: 3, Step : 900, LR : 3.8666022232962786e-07, Avg Loss : 0.0154\n",
            "Epoch: 3, Step : 910, LR : 3.624939584340261e-07, Avg Loss : 0.0301\n",
            "Epoch: 3, Step : 920, LR : 3.3832769453842437e-07, Avg Loss : 0.0279\n",
            "Epoch: 3, Step : 930, LR : 3.141614306428226e-07, Avg Loss : 0.0163\n",
            "Epoch: 3, Step : 940, LR : 2.899951667472209e-07, Avg Loss : 0.0168\n",
            "Epoch: 3, Step : 950, LR : 2.6582890285161913e-07, Avg Loss : 0.0154\n",
            "Epoch: 3, Step : 960, LR : 2.416626389560174e-07, Avg Loss : 0.0200\n",
            "Epoch: 3, Step : 970, LR : 2.1749637506041567e-07, Avg Loss : 0.0229\n",
            "Epoch: 3, Step : 980, LR : 1.9333011116481393e-07, Avg Loss : 0.0174\n",
            "Epoch: 3, Step : 990, LR : 1.6916384726921218e-07, Avg Loss : 0.0170\n",
            "Epoch: 3, Step : 1000, LR : 1.4499758337361044e-07, Avg Loss : 0.0167\n",
            "Epoch: 3, Step : 1010, LR : 1.208313194780087e-07, Avg Loss : 0.0208\n",
            "Epoch: 3, Step : 1020, LR : 9.666505558240696e-08, Avg Loss : 0.0180\n",
            "Epoch: 3, Step : 1030, LR : 7.249879168680522e-08, Avg Loss : 0.0208\n",
            "Epoch: 3, Step : 1040, LR : 4.833252779120348e-08, Avg Loss : 0.0225\n",
            "Epoch: 3, Step : 1050, LR : 2.416626389560174e-08, Avg Loss : 0.0199\n",
            "Epoch: 3, Step : 1060, LR : 0.0, Avg Loss : 0.0222\n",
            "Epoch 3 Total Mean Loss : 0.0191\n",
            "*****Epoch 3 Train Finish*****\n",
            "\n",
            "*****Epoch 3 Valid Start*****\n",
            "Step: 0,  Pearson: tensor([0.7603])\n",
            "Step: 1,  Pearson: tensor([0.8064])\n",
            "Step: 2,  Pearson: tensor([0.9125])\n",
            "Step: 3,  Pearson: tensor([0.8979])\n",
            "Step: 4,  Pearson: tensor([0.9455])\n",
            "Step: 5,  Pearson: tensor([0.8824])\n",
            "Step: 6,  Pearson: tensor([0.7513])\n",
            "Step: 7,  Pearson: tensor([0.9261])\n",
            "Step: 8,  Pearson: tensor([0.8476])\n",
            "Step: 9,  Pearson: tensor([0.7756])\n",
            "Step: 10,  Pearson: tensor([0.9042])\n",
            "Step: 11,  Pearson: tensor([0.7707])\n",
            "Step: 12,  Pearson: tensor([0.8239])\n",
            "Step: 13,  Pearson: tensor([0.6572])\n",
            "Step: 14,  Pearson: tensor([0.6159])\n",
            "Step: 15,  Pearson: tensor([0.7046])\n",
            "Step: 16,  Pearson: tensor([0.6201])\n",
            "Step: 17,  Pearson: tensor([0.8385])\n",
            "Step: 18,  Pearson: tensor([0.8503])\n",
            "Step: 19,  Pearson: tensor([0.7291])\n",
            "Step: 20,  Pearson: tensor([0.7941])\n",
            "Step: 21,  Pearson: tensor([0.8140])\n",
            "Step: 22,  Pearson: tensor([0.8177])\n",
            "Step: 23,  Pearson: tensor([0.8118])\n",
            "Step: 24,  Pearson: tensor([0.8719])\n",
            "Step: 25,  Pearson: tensor([0.8209])\n",
            "Step: 26,  Pearson: tensor([0.9045])\n",
            "Step: 27,  Pearson: tensor([0.7249])\n",
            "Step: 28,  Pearson: tensor([0.9037])\n",
            "Step: 29,  Pearson: tensor([0.7152])\n",
            "Step: 30,  Pearson: tensor([0.8663])\n",
            "Step: 31,  Pearson: tensor([0.9191])\n",
            "Step: 32,  Pearson: tensor([0.8556])\n",
            "Step: 33,  Pearson: tensor([0.9640])\n",
            "Step: 34,  Pearson: tensor([0.8945])\n",
            "Step: 35,  Pearson: tensor([0.8330])\n",
            "Step: 36,  Pearson: tensor([0.9162])\n",
            "Step: 37,  Pearson: tensor([0.9415])\n",
            "Step: 38,  Pearson: tensor([0.8755])\n",
            "Step: 39,  Pearson: tensor([0.9587])\n",
            "Step: 40,  Pearson: tensor([0.7658])\n",
            "Step: 41,  Pearson: tensor([0.7140])\n",
            "Step: 42,  Pearson: tensor([0.8010])\n",
            "Step: 43,  Pearson: tensor([0.8523])\n",
            "Step: 44,  Pearson: tensor([0.7731])\n",
            "Step: 45,  Pearson: tensor([0.9116])\n",
            "Step: 46,  Pearson: tensor([0.7897])\n",
            "Step: 47,  Pearson: tensor([0.8219])\n",
            "Step: 48,  Pearson: tensor([0.8162])\n",
            "Step: 49,  Pearson: tensor([0.8273])\n",
            "Step: 50,  Pearson: tensor([0.6535])\n",
            "Step: 51,  Pearson: tensor([0.7915])\n",
            "Step: 52,  Pearson: tensor([0.9102])\n",
            "Step: 53,  Pearson: tensor([0.7982])\n",
            "Step: 54,  Pearson: tensor([0.8820])\n",
            "Step: 55,  Pearson: tensor([0.9566])\n",
            "Step: 56,  Pearson: tensor([0.7957])\n",
            "Step: 57,  Pearson: tensor([0.8766])\n",
            "Step: 58,  Pearson: tensor([0.7401])\n",
            "Step: 59,  Pearson: tensor([0.8282])\n",
            "Step: 60,  Pearson: tensor([0.8504])\n",
            "Step: 61,  Pearson: tensor([0.8293])\n",
            "Step: 62,  Pearson: tensor([0.8250])\n",
            "Step: 63,  Pearson: tensor([0.9162])\n",
            "Step: 64,  Pearson: tensor([0.7856])\n",
            "Step: 65,  Pearson: tensor([0.8322])\n",
            "Step: 66,  Pearson: tensor([0.8886])\n",
            "Step: 67,  Pearson: tensor([0.8100])\n",
            "Step: 68,  Pearson: tensor([0.6356])\n",
            "Step: 69,  Pearson: tensor([0.8533])\n",
            "Step: 70,  Pearson: tensor([0.8239])\n",
            "Step: 71,  Pearson: tensor([0.8056])\n",
            "Step: 72,  Pearson: tensor([0.7241])\n",
            "Step: 73,  Pearson: tensor([0.8482])\n",
            "Step: 74,  Pearson: tensor([0.7518])\n",
            "Step: 75,  Pearson: tensor([0.8634])\n",
            "Step: 76,  Pearson: tensor([0.8636])\n",
            "Step: 77,  Pearson: tensor([0.7743])\n",
            "Step: 78,  Pearson: tensor([0.8268])\n",
            "Step: 79,  Pearson: tensor([0.8809])\n",
            "Step: 80,  Pearson: tensor([0.7612])\n",
            "Step: 81,  Pearson: tensor([0.7473])\n",
            "Step: 82,  Pearson: tensor([0.7757])\n",
            "Step: 83,  Pearson: tensor([0.9225])\n",
            "Step: 84,  Pearson: tensor([0.8959])\n",
            "Step: 85,  Pearson: tensor([0.8562])\n",
            "Step: 86,  Pearson: tensor([0.8481])\n",
            "Step: 87,  Pearson: tensor([0.8294])\n",
            "Step: 88,  Pearson: tensor([0.8318])\n",
            "Step: 89,  Pearson: tensor([0.8499])\n",
            "Step: 90,  Pearson: tensor([0.9036])\n",
            "Step: 91,  Pearson: tensor([0.9083])\n",
            "Step: 92,  Pearson: tensor([0.7802])\n",
            "Step: 93,  Pearson: tensor([0.8626])\n",
            "Step: 94,  Pearson: tensor([0.8850])\n",
            "Step: 95,  Pearson: tensor([0.8088])\n",
            "Step: 96,  Pearson: tensor([0.8404])\n",
            "Step: 97,  Pearson: tensor([0.7652])\n",
            "Step: 98,  Pearson: tensor([0.8043])\n",
            "Step: 99,  Pearson: tensor([0.7858])\n",
            "Step: 100,  Pearson: tensor([0.8775])\n",
            "Step: 101,  Pearson: tensor([0.8373])\n",
            "Step: 102,  Pearson: tensor([0.9626])\n",
            "Step: 103,  Pearson: tensor([0.8647])\n",
            "Step: 104,  Pearson: tensor([0.7972])\n",
            "Step: 105,  Pearson: tensor([0.8856])\n",
            "Step: 106,  Pearson: tensor([0.8638])\n",
            "Step: 107,  Pearson: tensor([0.8612])\n",
            "Step: 108,  Pearson: tensor([0.9061])\n",
            "Step: 109,  Pearson: tensor([0.8662])\n",
            "Step: 110,  Pearson: tensor([0.9155])\n",
            "Step: 111,  Pearson: tensor([0.8618])\n",
            "Step: 112,  Pearson: tensor([0.9193])\n",
            "Step: 113,  Pearson: tensor([0.8038])\n",
            "Step: 114,  Pearson: tensor([0.8332])\n",
            "Step: 115,  Pearson: tensor([0.8057])\n",
            "Step: 116,  Pearson: tensor([0.7295])\n",
            "Step: 117,  Pearson: tensor([0.7727])\n",
            "Step: 118,  Pearson: tensor([0.9383])\n",
            "Step: 119,  Pearson: tensor([0.8548])\n",
            "Step: 120,  Pearson: tensor([0.8727])\n",
            "Step: 121,  Pearson: tensor([0.7718])\n",
            "Step: 122,  Pearson: tensor([0.9450])\n",
            "Step: 123,  Pearson: tensor([0.7073])\n",
            "Step: 124,  Pearson: tensor([0.9269])\n",
            "Step: 125,  Pearson: tensor([0.8446])\n",
            "Step: 126,  Pearson: tensor([0.8708])\n",
            "Step: 127,  Pearson: tensor([0.8965])\n",
            "Step: 128,  Pearson: tensor([0.9602])\n",
            "Step: 129,  Pearson: tensor([0.8712])\n",
            "Step: 130,  Pearson: tensor([0.7473])\n",
            "Step: 131,  Pearson: tensor([0.8511])\n",
            "Step: 132,  Pearson: tensor([0.8169])\n",
            "Step: 133,  Pearson: tensor([0.8330])\n",
            "Step: 134,  Pearson: tensor([0.7580])\n",
            "Step: 135,  Pearson: tensor([0.8227])\n",
            "Step: 136,  Pearson: tensor([0.7296])\n",
            "Step: 137,  Pearson: tensor([0.9423])\n",
            "Step: 138,  Pearson: tensor([0.7345])\n",
            "Step: 139,  Pearson: tensor([0.9042])\n",
            "Step: 140,  Pearson: tensor([0.8569])\n",
            "Step: 141,  Pearson: tensor([0.7846])\n",
            "Step: 142,  Pearson: tensor([0.8549])\n",
            "Step: 143,  Pearson: tensor([0.8327])\n",
            "Step: 144,  Pearson: tensor([0.8900])\n",
            "Step: 145,  Pearson: tensor([0.9069])\n",
            "Step: 146,  Pearson: tensor([0.7854])\n",
            "Step: 147,  Pearson: tensor([0.8687])\n",
            "Step: 148,  Pearson: tensor([0.8190])\n",
            "Step: 149,  Pearson: tensor([0.8542])\n",
            "Step: 150,  Pearson: tensor([0.8767])\n",
            "Step: 151,  Pearson: tensor([0.9244])\n",
            "Step: 152,  Pearson: tensor([0.8824])\n",
            "Step: 153,  Pearson: tensor([0.6974])\n",
            "Step: 154,  Pearson: tensor([0.8199])\n",
            "Step: 155,  Pearson: tensor([0.8753])\n",
            "Step: 156,  Pearson: tensor([0.8697])\n",
            "Step: 157,  Pearson: tensor([0.9396])\n",
            "Step: 158,  Pearson: tensor([0.8663])\n",
            "Step: 159,  Pearson: tensor([0.8852])\n",
            "Step: 160,  Pearson: tensor([0.8697])\n",
            "Step: 161,  Pearson: tensor([0.9218])\n",
            "Step: 162,  Pearson: tensor([0.7324])\n",
            "Step: 163,  Pearson: tensor([0.8114])\n",
            "Step: 164,  Pearson: tensor([0.9090])\n",
            "Step: 165,  Pearson: tensor([0.9308])\n",
            "Step: 166,  Pearson: tensor([0.9002])\n",
            "Step: 167,  Pearson: tensor([0.8045])\n",
            "Step: 168,  Pearson: tensor([0.7836])\n",
            "Step: 169,  Pearson: tensor([0.8413])\n",
            "Step: 170,  Pearson: tensor([0.8646])\n",
            "Step: 171,  Pearson: tensor([0.9063])\n",
            "Step: 172,  Pearson: tensor([0.9435])\n",
            "Step: 173,  Pearson: tensor([0.7905])\n",
            "Step: 174,  Pearson: tensor([0.9125])\n",
            "Step: 175,  Pearson: tensor([0.6721])\n",
            "Step: 176,  Pearson: tensor([0.8879])\n",
            "Step: 177,  Pearson: tensor([0.8921])\n",
            "Step: 178,  Pearson: tensor([0.8361])\n",
            "Step: 179,  Pearson: tensor([0.6919])\n",
            "Step: 180,  Pearson: tensor([0.7834])\n",
            "Step: 181,  Pearson: tensor([0.8379])\n",
            "Step: 182,  Pearson: tensor([0.6522])\n",
            "Step: 183,  Pearson: tensor([0.8613])\n",
            "Step: 184,  Pearson: tensor([0.7704])\n",
            "Step: 185,  Pearson: tensor([0.8637])\n",
            "Step: 186,  Pearson: tensor([0.8211])\n",
            "Step: 187,  Pearson: tensor([0.8667])\n",
            "Step: 188,  Pearson: tensor([0.8285])\n",
            "Step: 189,  Pearson: tensor([0.8068])\n",
            "Step: 190,  Pearson: tensor([0.8397])\n",
            "Step: 191,  Pearson: tensor([0.7958])\n",
            "Step: 192,  Pearson: tensor([0.7700])\n",
            "Step: 193,  Pearson: tensor([0.7955])\n",
            "Step: 194,  Pearson: tensor([0.8685])\n",
            "Step: 195,  Pearson: tensor([0.8552])\n",
            "Step: 196,  Pearson: tensor([0.8619])\n",
            "Step: 197,  Pearson: tensor([0.8499])\n",
            "Step: 198,  Pearson: tensor([0.8222])\n",
            "Step: 199,  Pearson: tensor([0.9338])\n",
            "Step: 200,  Pearson: tensor([0.8381])\n",
            "Step: 201,  Pearson: tensor([0.8522])\n",
            "Step: 202,  Pearson: tensor([0.8398])\n",
            "Step: 203,  Pearson: tensor([0.9056])\n",
            "Step: 204,  Pearson: tensor([0.9626])\n",
            "Step: 205,  Pearson: tensor([0.8687])\n",
            "Step: 206,  Pearson: tensor([0.8777])\n",
            "Step: 207,  Pearson: tensor([0.7715])\n",
            "Step: 208,  Pearson: tensor([0.7985])\n",
            "Step: 209,  Pearson: tensor([0.8683])\n",
            "Step: 210,  Pearson: tensor([0.8810])\n",
            "Step: 211,  Pearson: tensor([0.8738])\n",
            "Step: 212,  Pearson: tensor([0.8427])\n",
            "Step: 213,  Pearson: tensor([0.7174])\n",
            "Step: 214,  Pearson: tensor([0.7643])\n",
            "Step: 215,  Pearson: tensor([0.7942])\n",
            "Step: 216,  Pearson: tensor([0.7632])\n",
            "Step: 217,  Pearson: tensor([0.8205])\n",
            "Step: 218,  Pearson: tensor([0.7509])\n",
            "Step: 219,  Pearson: tensor([0.8940])\n",
            "Step: 220,  Pearson: tensor([0.7451])\n",
            "Step: 221,  Pearson: tensor([0.9648])\n",
            "Step: 222,  Pearson: tensor([0.8384])\n",
            "Step: 223,  Pearson: tensor([0.9109])\n",
            "Step: 224,  Pearson: tensor([0.8817])\n",
            "Step: 225,  Pearson: tensor([0.9212])\n",
            "Step: 226,  Pearson: tensor([0.6930])\n",
            "Step: 227,  Pearson: tensor([0.7803])\n",
            "Epoch 3 Valid Loss : 0.07473009733254449 Valid Pearsonr : tensor([0.8361]) ValidF1 : 0.14472177696359056\n",
            "*****Epoch 3 Valid Finish*****\n",
            "\n",
            "SAVING EPOCH 3 ...\n",
            "** Train Completed! **\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_dataloader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_prediction = []\n",
        "    all_reallabel = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "        batch = tuple(items.to(device) for items in batch)\n",
        "\n",
        "        (x_batch_one, x_batch_two, batch_y) = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logit = model(x_batch_one, x_batch_two)\n",
        "        logit = logit*5\n",
        "\n",
        "        logit = logit.cpu()\n",
        "        batch_y = batch_y.cpu()\n",
        "\n",
        "        all_prediction = all_prediction + logit.tolist()\n",
        "        all_reallabel = all_reallabel + batch_y.tolist()\n",
        "\n",
        "    pred = torch.Tensor(all_prediction) # x\n",
        "    real = torch.Tensor(all_reallabel) # y\n",
        "    \n",
        "    pearson = pearsonr(pred, real) #stats.spearmanr(pred, real)\n",
        "\n",
        "    #f1\n",
        "    fone = f1_process(pred, real)\n",
        "\n",
        "    return pearson, fone"
      ],
      "metadata": {
        "id": "y4PqBp0o-JQh"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt1 = '/content/drive/MyDrive/data/checkpoints/sts_vx.ckpt.0'\n",
        "ckpt2 = '/content/drive/MyDrive/data/checkpoints/sts_vx.ckpt.1'\n",
        "ckpt3 = '/content/drive/MyDrive/data/checkpoints/sts_vx.ckpt.2'\n",
        "ckpt4 = '/content/drive/MyDrive/data/checkpoints/sts_vx.ckpt.3'"
      ],
      "metadata": {
        "id": "ipIQGv_r4QdK"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_checkpoints = [ckpt1, ckpt2, ckpt3, ckpt4]\n",
        "\n",
        "for checkpoint in all_checkpoints:\n",
        "    loaded_ckpt = torch.load(checkpoint)\n",
        "    model, optimizer, scheduler = initializer(train_dataloader, 1)\n",
        "    model.load_state_dict(loaded_ckpt['model_state_dict'])\n",
        "    pearson_score, fonescore = predict(model, test_dataloader)\n",
        "    print(f'{checkpoint[44:]} pearsonr: {pearson_score}, f1_score: {fonescore}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUpgKAMy4SIL",
        "outputId": "95fdd108-4796-4f4e-ea0e-06ddd82148f3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total step: 1061\n",
            "vx.ckpt.0 pearsonr: tensor([0.7127]), f1_score: 0.7073954983922829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total step: 1061\n",
            "vx.ckpt.1 pearsonr: tensor([0.7115]), f1_score: 0.7236842105263158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total step: 1061\n",
            "vx.ckpt.2 pearsonr: tensor([0.7065]), f1_score: 0.7296849087893864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total step: 1061\n",
            "vx.ckpt.3 pearsonr: tensor([0.7075]), f1_score: 0.7345575959933222\n"
          ]
        }
      ]
    }
  ]
}